{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2_ML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "tka-kJWdXIsg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import exp\n",
        "from random import randrange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KPiy1etViAT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q1: LDA"
      ]
    },
    {
      "metadata": {
        "id": "qwkZs0Jgh_Ce",
        "colab_type": "code",
        "outputId": "cd2d7462-0c40-42aa-fd63-624d1595785e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"iris.data.txt\", header=None)\n",
        "# df = pd.read_csv(\"iris.data.txt\", names=['sepal length','sepal width','petal length','petal width','class'])\n",
        "print(df.head())\n",
        "df.iloc[:,-1] = df.iloc[:,-1].apply(lambda x: 1 if x == 'Iris-setosa' else x)\n",
        "df.iloc[:,-1] = df.iloc[:,-1].apply(lambda x: 2 if x == 'Iris-versicolor' else x)\n",
        "df.iloc[:,-1] = df.iloc[:,-1].apply(lambda x: 3 if x == 'Iris-virginica' else x)\n",
        "# df['class']\n",
        "# df.corr()\n",
        "# X = df[['sepal length','sepal width','petal length','petal width']]\n",
        "# y = df['class']\n",
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0    1    2    3            4\n",
            "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
            "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
            "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
            "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
            "4  5.0  3.6  1.4  0.2  Iris-setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8SYuNHopYDF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7990
        },
        "outputId": "66fe6912-01db-48f6-e930-8d80c775b746"
      },
      "cell_type": "code",
      "source": [
        "# IMP ##################333# after whole function is done, make it modular #######################3\n",
        "\n",
        "#Using Fisher's Linear Discriminant\n",
        "def LDA(c1,c2):  \n",
        "  # mean vectors for class c1 and c2\n",
        "  m1 = np.mean(X[y==c1], axis=0)\n",
        "  m2 = np.mean(X[y==c2], axis=0)\n",
        "  \n",
        "  # Within class scatter matrix for both classes\n",
        "  # we have 4 features in out dataset, hence dimension for scatter matrices will be 4x4\n",
        "  Sw = np.zeros((4,4))\n",
        "  \n",
        "  # s1 - within scatter matrix of class c1\n",
        "  s1 = np.zeros((4,4))\n",
        "  for data in X[y==c1]:\n",
        "    # make column vectors\n",
        "    data = data.reshape(4,1)\n",
        "    m1 = m1.reshape(4,1) \n",
        "    \n",
        "    s1 += (data-m1).dot((data-m1).T)\n",
        "    \n",
        "  # s2 - within scatter matrix of class c2\n",
        "  s2 = np.zeros((4,4))\n",
        "  for data in X[y==c2]:\n",
        "    # make column vectors\n",
        "    data = data.reshape(4,1)\n",
        "    m2 = m2.reshape(4,1) \n",
        "    \n",
        "    s2 += (data-m2).dot((data-m2).T)\n",
        "   \n",
        "  Sw = s1 + s2\n",
        "  \n",
        "  # Between class scatter matrix for both classes\n",
        "  # here also, dimension for scatter matrices will be 4x4\n",
        "  Sb = np.zeros((4,4))\n",
        "  \n",
        "  # total mean \n",
        "  M = np.mean(X, axis=0)\n",
        "  \n",
        "  # make column vectors\n",
        "  M = M.reshape(4,1)\n",
        "  \n",
        "  n1 = X[y==c1,:].shape[0]\n",
        "  n2 = X[y==c2,:].shape[0]\n",
        "#   print(n1)\n",
        "  \n",
        "  sb1 = n1 * (m1 - M).dot((m1 - M).T)\n",
        "  sb2 = n2 * (m2 - M).dot((m2 - M).T)\n",
        "    \n",
        "  Sb = sb1 + sb2\n",
        "  \n",
        "  # Solving the generalized eigenvalue problem\n",
        "  eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))\n",
        "\n",
        "  # sorting pairs:(eigenvalue, eigenvector) to get the top largest eigen values\n",
        "  eigen_val_vec = sorted([(np.abs(eigen_values[v]), eigen_vectors[:,v]) for v in range(len(eigen_values))], key=lambda i: i[0], reverse=True)\n",
        "  \n",
        "  # Solving for W from eigen pairs\n",
        "  # As we can see top 2 eigen values retain most of the details, hence we can convert from 4D to 2D subspace\n",
        "  W = np.hstack((eigen_val_vec[0][1].reshape(4,1), eigen_val_vec[1][1].reshape(4,1)))\n",
        "#   print('W:\\n', W)\n",
        "  \n",
        "  # from Y = X*W\n",
        "  lda = X.dot(W)\n",
        "  \n",
        "  return lda\n",
        "  \n",
        "print(\"For classes 1 and 2:\")\n",
        "print(LDA(1,2))\n",
        "print(\"For classes 2 and 3:\")\n",
        "print(LDA(2,3))\n",
        "print(\"For classes 1 and 3:\")\n",
        "print(LDA(1,3))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For classes 1 and 2:\n",
            "[[-0.90191257+0.j -0.46482296+0.j]\n",
            " [-0.69557496+0.j -0.35797646+0.j]\n",
            " [-0.80431627+0.j -0.4340149 +0.j]\n",
            " [-0.67164226+0.j -0.34515468+0.j]\n",
            " [-0.934375  +0.j -0.48599102+0.j]\n",
            " [-0.78261196+0.j -0.63280585+0.j]\n",
            " [-0.75085081+0.j -0.53449814+0.j]\n",
            " [-0.813055  +0.j -0.40966508+0.j]\n",
            " [-0.62537644+0.j -0.33594591+0.j]\n",
            " [-0.77137355+0.j -0.2538802 +0.j]\n",
            " [-0.95446775+0.j -0.47417548+0.j]\n",
            " [-0.75665987+0.j -0.37567524+0.j]\n",
            " [-0.77014885+0.j -0.26612699+0.j]\n",
            " [-0.87015142+0.j -0.36651526+0.j]\n",
            " [-1.2273298 +0.j -0.63979289+0.j]\n",
            " [-1.08287179+0.j -0.80720077+0.j]\n",
            " [-0.95787771+0.j -0.76761519+0.j]\n",
            " [-0.82104933+0.j -0.55652868+0.j]\n",
            " [-0.84359146+0.j -0.52021957+0.j]\n",
            " [-0.89348824+0.j -0.58676175+0.j]\n",
            " [-0.75057953+0.j -0.3428354 +0.j]\n",
            " [-0.77387322+0.j -0.65715567+0.j]\n",
            " [-1.08448336+0.j -0.62022537+0.j]\n",
            " [-0.45036998+0.j -0.59620951+0.j]\n",
            " [-0.62521056+0.j -0.27456823+0.j]\n",
            " [-0.61423144+0.j -0.29071553+0.j]\n",
            " [-0.60751209+0.j -0.55937418+0.j]\n",
            " [-0.86438548+0.j -0.43126438+0.j]\n",
            " [-0.86945014+0.j -0.44365491+0.j]\n",
            " [-0.67286696+0.j -0.33290789+0.j]\n",
            " [-0.64040452+0.j -0.31173984+0.j]\n",
            " [-0.67648592+0.j -0.59365151+0.j]\n",
            " [-1.17775941+0.j -0.46742947+0.j]\n",
            " [-1.19833244+0.j -0.61458057+0.j]\n",
            " [-0.77137355+0.j -0.2538802 +0.j]\n",
            " [-0.86700075+0.j -0.46814848+0.j]\n",
            " [-0.9708864 +0.j -0.4991003 +0.j]\n",
            " [-0.77137355+0.j -0.2538802 +0.j]\n",
            " [-0.70794466+0.j -0.39096005+0.j]\n",
            " [-0.81934435+0.j -0.40980883+0.j]\n",
            " [-0.85857642+0.j -0.59008727+0.j]\n",
            " [-0.36210829+0.j -0.33362691+0.j]\n",
            " [-0.78544822+0.j -0.43358366+0.j]\n",
            " [-0.48453739+0.j -0.76409742+0.j]\n",
            " [-0.63735926+0.j -0.54365812+0.j]\n",
            " [-0.60842238+0.j -0.44953843+0.j]\n",
            " [-0.93053504+0.j -0.4613537 +0.j]\n",
            " [-0.75421048+0.j -0.40016882+0.j]\n",
            " [-0.9481784 +0.j -0.47403173+0.j]\n",
            " [-0.81811966+0.j -0.42205561+0.j]\n",
            " [ 1.51114643+0.j -0.39191029+0.j]\n",
            " [ 1.54211288+0.j -0.55015819+0.j]\n",
            " [ 1.72468367+0.j -0.39475579+0.j]\n",
            " [ 1.5666744 +0.j -0.34215849+0.j]\n",
            " [ 1.7346471 +0.j -0.4313524 +0.j]\n",
            " [ 1.57941898+0.j -0.28049331+0.j]\n",
            " [ 1.67814656+0.j -0.59562729+0.j]\n",
            " [ 1.01635394+0.j -0.323407  +0.j]\n",
            " [ 1.52787949+0.j -0.26939651+0.j]\n",
            " [ 1.46758212+0.j -0.5523825 +0.j]\n",
            " [ 1.25270459+0.j -0.17089886+0.j]\n",
            " [ 1.51961388+0.j -0.60792286+0.j]\n",
            " [ 1.33138972+0.j -0.04644827+0.j]\n",
            " [ 1.68400591+0.j -0.32668115+0.j]\n",
            " [ 1.15260861+0.j -0.60498239+0.j]\n",
            " [ 1.43731694+0.j -0.47127426+0.j]\n",
            " [ 1.66993124+0.j -0.5063846 +0.j]\n",
            " [ 1.19402595+0.j -0.11901744+0.j]\n",
            " [ 1.9422094 +0.j -0.33675268+0.j]\n",
            " [ 1.27733857+0.j -0.23521674+0.j]\n",
            " [ 1.94759866+0.j -0.7234496 +0.j]\n",
            " [ 1.3351794 +0.j -0.44957999+0.j]\n",
            " [ 1.99493046+0.j -0.26602248+0.j]\n",
            " [ 1.56103122+0.j -0.12195791+0.j]\n",
            " [ 1.40900888+0.j -0.37021602+0.j]\n",
            " [ 1.48235808+0.j -0.4498187 +0.j]\n",
            " [ 1.72254869+0.j -0.27267325+0.j]\n",
            " [ 1.98155706+0.j -0.52286559+0.j]\n",
            " [ 1.68352563+0.j -0.48564779+0.j]\n",
            " [ 0.97616846+0.j -0.29977592+0.j]\n",
            " [ 1.27856327+0.j -0.24746352+0.j]\n",
            " [ 1.15388359+0.j -0.18946014+0.j]\n",
            " [ 1.26811955+0.j -0.36983356+0.j]\n",
            " [ 2.10479105+0.j -0.33251589+0.j]\n",
            " [ 1.68250994+0.j -0.5060971 +0.j]\n",
            " [ 1.57062995+0.j -0.68391252+0.j]\n",
            " [ 1.64962949+0.j -0.46187296+0.j]\n",
            " [ 1.69162536+0.j -0.20849913+0.j]\n",
            " [ 1.33293902+0.j -0.45778251+0.j]\n",
            " [ 1.48917084+0.j -0.38478209+0.j]\n",
            " [ 1.54482156+0.j -0.17957882+0.j]\n",
            " [ 1.60143769+0.j -0.38169529+0.j]\n",
            " [ 1.35068777+0.j -0.31481942+0.j]\n",
            " [ 1.04881637+0.j -0.30223894+0.j]\n",
            " [ 1.4930108 +0.j -0.36014477+0.j]\n",
            " [ 1.28960286+0.j -0.3325182 +0.j]\n",
            " [ 1.40921789+0.j -0.40291212+0.j]\n",
            " [ 1.42158758+0.j -0.36992853+0.j]\n",
            " [ 0.91443739+0.j -0.53781903+0.j]\n",
            " [ 1.40415323+0.j -0.41530266+0.j]\n",
            " [ 2.97552939+0.j -0.98284838+0.j]\n",
            " [ 2.35995946+0.j -0.60734555+0.j]\n",
            " [ 2.67420055+0.j -0.58694243+0.j]\n",
            " [ 2.3892281 +0.j -0.39047049+0.j]\n",
            " [ 2.74898345+0.j -0.71148799+0.j]\n",
            " [ 2.94946887+0.j -0.35174481+0.j]\n",
            " [ 2.06944207+0.j -0.58223079+0.j]\n",
            " [ 2.63304967+0.j -0.15599162+0.j]\n",
            " [ 2.60671071+0.j -0.2383936 +0.j]\n",
            " [ 2.84648634+0.j -1.01437519+0.j]\n",
            " [ 2.20303835+0.j -0.80661652+0.j]\n",
            " [ 2.40985624+0.j -0.54080337+0.j]\n",
            " [ 2.51780285+0.j -0.72132053+0.j]\n",
            " [ 2.48079918+0.j -0.68998625+0.j]\n",
            " [ 2.72552387+0.j -1.08718595+0.j]\n",
            " [ 2.53955029+0.j -1.01418525+0.j]\n",
            " [ 2.29408118+0.j -0.44577213+0.j]\n",
            " [ 2.75784494+0.j -0.58038636+0.j]\n",
            " [ 3.39136244+0.j -0.34894578+0.j]\n",
            " [ 2.17387029+0.j -0.1679535 +0.j]\n",
            " [ 2.68336929+0.j -0.88009465+0.j]\n",
            " [ 2.32701674+0.j -0.78748025+0.j]\n",
            " [ 2.98363628+0.j -0.1838569 +0.j]\n",
            " [ 2.16001661+0.j -0.58376325+0.j]\n",
            " [ 2.49546973+0.j -0.71770751+0.j]\n",
            " [ 2.39163436+0.j -0.32089029+0.j]\n",
            " [ 2.08373774+0.j -0.63863364+0.j]\n",
            " [ 2.05633996+0.j -0.64741115+0.j]\n",
            " [ 2.66428025+0.j -0.64441959+0.j]\n",
            " [ 2.21977858+0.j -0.16225992+0.j]\n",
            " [ 2.65874247+0.j -0.29393396+0.j]\n",
            " [ 2.45209045+0.j -0.49836943+0.j]\n",
            " [ 2.74514349+0.j -0.73612531+0.j]\n",
            " [ 1.96630798+0.j -0.26255322+0.j]\n",
            " [ 2.19460919+0.j  0.04057529+0.j]\n",
            " [ 2.88582381+0.j -0.70381168+0.j]\n",
            " [ 2.68064862+0.j -1.04726382+0.j]\n",
            " [ 2.26161875+0.j -0.46694018+0.j]\n",
            " [ 2.01881287+0.j -0.68096974+0.j]\n",
            " [ 2.42894529+0.j -0.77647842+0.j]\n",
            " [ 2.77174657+0.j -0.9839034 +0.j]\n",
            " [ 2.45922245+0.j -1.06099687+0.j]\n",
            " [ 2.35995946+0.j -0.60734555+0.j]\n",
            " [ 2.77729151+0.j -0.81254622+0.j]\n",
            " [ 2.81892268+0.j -1.08453039+0.j]\n",
            " [ 2.55436937+0.j -1.00569523+0.j]\n",
            " [ 2.36219985+0.j -0.59914302+0.j]\n",
            " [ 2.32435835+0.j -0.73029058+0.j]\n",
            " [ 2.51844186+0.j -1.02281902+0.j]\n",
            " [ 2.15655153+0.j -0.57971898+0.j]]\n",
            "For classes 2 and 3:\n",
            "[[-2.20985248e+00 -2.62758450e+00]\n",
            " [-1.90241025e+00 -2.25136049e+00]\n",
            " [-2.00818950e+00 -2.41054936e+00]\n",
            " [-1.83261406e+00 -2.28480650e+00]\n",
            " [-2.23781268e+00 -2.69535522e+00]\n",
            " [-2.20943506e+00 -2.99264659e+00]\n",
            " [-1.97303834e+00 -2.59155754e+00]\n",
            " [-2.08413591e+00 -2.52548908e+00]\n",
            " [-1.73075753e+00 -2.15155798e+00]\n",
            " [-1.96962174e+00 -2.23704685e+00]\n",
            " [-2.33565776e+00 -2.76617166e+00]\n",
            " [-1.98637953e+00 -2.49116438e+00]\n",
            " [-1.94362292e+00 -2.18224630e+00]\n",
            " [-1.97345577e+00 -2.22649545e+00]\n",
            " [-2.73675624e+00 -3.07779654e+00]\n",
            " [-2.64054380e+00 -3.42150411e+00]\n",
            " [-2.40887056e+00 -3.08723633e+00]\n",
            " [-2.14469106e+00 -2.69136005e+00]\n",
            " [-2.29453380e+00 -2.87177759e+00]\n",
            " [-2.25055902e+00 -2.88704066e+00]\n",
            " [-2.08021318e+00 -2.49954874e+00]\n",
            " [-2.13348865e+00 -2.87770686e+00]\n",
            " [-2.34145315e+00 -2.76859043e+00]\n",
            " [-1.76097370e+00 -2.60175015e+00]\n",
            " [-1.83680291e+00 -2.42022208e+00]\n",
            " [-1.82664125e+00 -2.20940425e+00]\n",
            " [-1.90395419e+00 -2.62939275e+00]\n",
            " [-2.18394236e+00 -2.60927570e+00]\n",
            " [-2.18189229e+00 -2.55981378e+00]\n",
            " [-1.85861288e+00 -2.33960705e+00]\n",
            " [-1.83065269e+00 -2.27183633e+00]\n",
            " [-2.04960808e+00 -2.67439471e+00]\n",
            " [-2.56055746e+00 -2.98415625e+00]\n",
            " [-2.66901012e+00 -3.16070448e+00]\n",
            " [-1.96962174e+00 -2.23704685e+00]\n",
            " [-2.12989464e+00 -2.45021269e+00]\n",
            " [-2.35550638e+00 -2.67258646e+00]\n",
            " [-1.96962174e+00 -2.23704685e+00]\n",
            " [-1.83252535e+00 -2.24831476e+00]\n",
            " [-2.10808466e+00 -2.53082772e+00]\n",
            " [-2.17060118e+00 -2.70966885e+00]\n",
            " [-1.42795006e+00 -1.80566349e+00]\n",
            " [-1.93634324e+00 -2.39453346e+00]\n",
            " [-1.82554028e+00 -2.83005320e+00]\n",
            " [-1.98596210e+00 -2.85622647e+00]\n",
            " [-1.81330007e+00 -2.30979740e+00]\n",
            " [-2.26586157e+00 -2.79961768e+00]\n",
            " [-1.93438188e+00 -2.38156329e+00]\n",
            " [-2.31170901e+00 -2.76083303e+00]\n",
            " [-2.08208584e+00 -2.47602717e+00]\n",
            " [-8.18720472e-02 -2.49463171e+00]\n",
            " [ 2.72641557e-02 -2.57367034e+00]\n",
            " [ 1.58864825e-01 -2.43266441e+00]\n",
            " [ 3.30366236e-01 -1.85832457e+00]\n",
            " [ 2.60810057e-01 -2.26292414e+00]\n",
            " [ 2.72218370e-01 -2.11631141e+00]\n",
            " [ 1.64183137e-01 -2.65792174e+00]\n",
            " [-1.22346574e-01 -1.87360752e+00]\n",
            " [ 5.46295088e-02 -2.21382102e+00]\n",
            " [ 2.09879268e-01 -2.22216906e+00]\n",
            " [ 1.61058202e-01 -1.53921389e+00]\n",
            " [ 1.01249197e-01 -2.47170078e+00]\n",
            " [ 6.70471368e-02 -1.62058174e+00]\n",
            " [ 2.89393579e-01 -2.22725597e+00]\n",
            " [-2.04471687e-01 -2.39690905e+00]\n",
            " [-1.07693461e-01 -2.47644877e+00]\n",
            " [ 3.22672082e-01 -2.38474258e+00]\n",
            " [-9.47412078e-02 -1.95180378e+00]\n",
            " [ 5.94251120e-01 -1.83189958e+00]\n",
            " [ 2.24178683e-02 -1.90597824e+00]\n",
            " [ 4.92068823e-01 -2.66736152e+00]\n",
            " [-7.28710178e-02 -2.25590312e+00]\n",
            " [ 6.14011025e-01 -1.96197652e+00]\n",
            " [ 2.10979676e-01 -2.02659552e+00]\n",
            " [-4.70496045e-02 -2.27408606e+00]\n",
            " [-3.18357606e-02 -2.39800079e+00]\n",
            " [ 2.23520118e-01 -2.16786961e+00]\n",
            " [ 4.38853002e-01 -2.45278146e+00]\n",
            " [ 2.78786010e-01 -2.33298776e+00]\n",
            " [-3.18036752e-01 -2.01524041e+00]\n",
            " [ 4.84166942e-02 -1.85117769e+00]\n",
            " [-6.66036041e-02 -1.81104958e+00]\n",
            " [-6.41361073e-02 -2.12664975e+00]\n",
            " [ 7.46918570e-01 -2.10866000e+00]\n",
            " [ 3.70569591e-01 -2.37406532e+00]\n",
            " [ 8.44027068e-02 -2.76231006e+00]\n",
            " [ 1.07044586e-01 -2.46928202e+00]\n",
            " [ 3.38211697e-01 -1.80644389e+00]\n",
            " [-7.08626250e-03 -2.35178122e+00]\n",
            " [ 2.26548345e-01 -2.00454327e+00]\n",
            " [ 3.08913472e-01 -1.91928733e+00]\n",
            " [ 1.87625760e-01 -2.32401276e+00]\n",
            " [ 3.76317123e-02 -2.02989297e+00]\n",
            " [-9.43863825e-02 -1.80583681e+00]\n",
            " [ 1.98499448e-01 -2.10880574e+00]\n",
            " [-4.63375672e-02 -2.26969687e+00]\n",
            " [ 7.07328026e-02 -2.26036307e+00]\n",
            " [ 8.47904408e-04 -2.26340879e+00]\n",
            " [-3.06568226e-01 -2.09211199e+00]\n",
            " [ 7.27828741e-02 -2.21090115e+00]\n",
            " [ 1.39880132e+00 -2.92448503e+00]\n",
            " [ 9.90300351e-01 -2.28930939e+00]\n",
            " [ 1.05243355e+00 -2.51641128e+00]\n",
            " [ 9.50871634e-01 -2.28020852e+00]\n",
            " [ 1.21142862e+00 -2.57180247e+00]\n",
            " [ 1.28170189e+00 -2.37757239e+00]\n",
            " [ 8.80180940e-01 -2.10937651e+00]\n",
            " [ 1.06039621e+00 -2.16806280e+00]\n",
            " [ 1.16243015e+00 -1.96183078e+00]\n",
            " [ 1.07739457e+00 -3.16821334e+00]\n",
            " [ 6.28275767e-01 -2.75600211e+00]\n",
            " [ 9.46325573e-01 -2.27404631e+00]\n",
            " [ 9.24844315e-01 -2.59498512e+00]\n",
            " [ 1.13336955e+00 -2.22517504e+00]\n",
            " [ 1.26419853e+00 -2.68129649e+00]\n",
            " [ 9.47426542e-01 -2.89469526e+00]\n",
            " [ 8.01206306e-01 -2.38764257e+00]\n",
            " [ 9.57501874e-01 -3.00791394e+00]\n",
            " [ 1.74528839e+00 -2.14708242e+00]\n",
            " [ 8.91442999e-01 -1.70298514e+00]\n",
            " [ 1.02711827e+00 -2.82679868e+00]\n",
            " [ 9.51732591e-01 -2.46281189e+00]\n",
            " [ 1.34626848e+00 -2.14926934e+00]\n",
            " [ 7.05677407e-01 -2.29952187e+00]\n",
            " [ 8.92783981e-01 -2.76167967e+00]\n",
            " [ 7.79041504e-01 -2.45299452e+00]\n",
            " [ 6.27858342e-01 -2.39094002e+00]\n",
            " [ 5.97848079e-01 -2.50817265e+00]\n",
            " [ 1.17431610e+00 -2.40376446e+00]\n",
            " [ 6.52818798e-01 -2.22651959e+00]\n",
            " [ 1.05380008e+00 -2.21136250e+00]\n",
            " [ 6.29704894e-01 -2.96198241e+00]\n",
            " [ 1.23947752e+00 -2.46754001e+00]\n",
            " [ 5.58001936e-01 -2.13400970e+00]\n",
            " [ 8.93850282e-01 -1.79510101e+00]\n",
            " [ 1.13878162e+00 -2.62869930e+00]\n",
            " [ 1.08229545e+00 -3.02840857e+00]\n",
            " [ 7.73246115e-01 -2.45541329e+00]\n",
            " [ 5.71937959e-01 -2.52648146e+00]\n",
            " [ 7.99127741e-01 -2.69708054e+00]\n",
            " [ 1.14222727e+00 -2.83043505e+00]\n",
            " [ 7.79873968e-01 -2.89557394e+00]\n",
            " [ 9.90300351e-01 -2.28930939e+00]\n",
            " [ 1.15078477e+00 -2.77416518e+00]\n",
            " [ 1.15342968e+00 -3.01678187e+00]\n",
            " [ 9.29539296e-01 -2.78813989e+00]\n",
            " [ 9.24515596e-01 -2.19343128e+00]\n",
            " [ 7.81952532e-01 -2.58613598e+00]\n",
            " [ 9.41365034e-01 -3.00658926e+00]\n",
            " [ 7.45463336e-01 -2.45020052e+00]]\n",
            "For classes 1 and 3:\n",
            "[[ 1.17221181+0.j  2.1617996 +0.j]\n",
            " [ 1.00357823+0.j  1.80597345+0.j]\n",
            " [ 1.05768916+0.j  1.98203486+0.j]\n",
            " [ 0.87642015+0.j  1.87924303+0.j]\n",
            " [ 1.16659688+0.j  2.24105667+0.j]\n",
            " [ 1.01724225+0.j  2.516261  +0.j]\n",
            " [ 0.94262183+0.j  2.18248892+0.j]\n",
            " [ 1.0562836 +0.j  2.07655504+0.j]\n",
            " [ 0.8405861 +0.j  1.7613957 +0.j]\n",
            " [ 1.02732153+0.j  1.7966363 +0.j]\n",
            " [ 1.23614704+0.j  2.27386704+0.j]\n",
            " [ 0.93474045+0.j  2.07056755+0.j]\n",
            " [ 1.0420749 +0.j  1.74648627+0.j]\n",
            " [ 1.0975914 +0.j  1.82802751+0.j]\n",
            " [ 1.61203286+0.j  2.52382085+0.j]\n",
            " [ 1.34465859+0.j  2.9014018 +0.j]\n",
            " [ 1.27860542+0.j  2.58645007+0.j]\n",
            " [ 1.10561396+0.j  2.22706666+0.j]\n",
            " [ 1.14565738+0.j  2.36017709+0.j]\n",
            " [ 1.10773191+0.j  2.42995095+0.j]\n",
            " [ 1.03800672+0.j  2.01834095+0.j]\n",
            " [ 1.01864781+0.j  2.42174083+0.j]\n",
            " [ 1.31555534+0.j  2.33436529+0.j]\n",
            " [ 0.7314234 +0.j  2.15800462+0.j]\n",
            " [ 0.73871807+0.j  2.01792575+0.j]\n",
            " [ 0.90099782+0.j  1.76509903+0.j]\n",
            " [ 0.85774711+0.j  2.1895419 +0.j]\n",
            " [ 1.1349722 +0.j  2.13847245+0.j]\n",
            " [ 1.17782674+0.j  2.08254253+0.j]\n",
            " [ 0.86166678+0.j  1.92939306+0.j]\n",
            " [ 0.86728172+0.j  1.85013599+0.j]\n",
            " [ 1.03549261+0.j  2.18396961+0.j]\n",
            " [ 1.33648752+0.j  2.51406849+0.j]\n",
            " [ 1.44202023+0.j  2.65302035+0.j]\n",
            " [ 1.02732153+0.j  1.7966363 +0.j]\n",
            " [ 1.20733348+0.j  1.98224247+0.j]\n",
            " [ 1.34995731+0.j  2.15622732+0.j]\n",
            " [ 1.02732153+0.j  1.7966363 +0.j]\n",
            " [ 0.92841314+0.j  1.85242016+0.j]\n",
            " [ 1.08438477+0.j  2.07077515+0.j]\n",
            " [ 1.14285358+0.j  2.25039382+0.j]\n",
            " [ 0.73251275+0.j  1.39756703+0.j]\n",
            " [ 0.97338563+0.j  1.99937453+0.j]\n",
            " [ 0.74703765+0.j  2.39355321+0.j]\n",
            " [ 0.77977089+0.j  2.42502895+0.j]\n",
            " [ 0.90887921+0.j  1.8770204 +0.j]\n",
            " [ 1.10898896+0.j  2.34713662+0.j]\n",
            " [ 0.96424719+0.j  1.97026748+0.j]\n",
            " [ 1.20804586+0.j  2.27964693+0.j]\n",
            " [ 1.09913814+0.j  2.02062512+0.j]\n",
            " [-1.3167449 +0.j  2.03569513+0.j]\n",
            " [-1.42126822+0.j  2.17073606+0.j]\n",
            " [-1.56461175+0.j  1.99817037+0.j]\n",
            " [-1.41665536+0.j  1.51866259+0.j]\n",
            " [-1.54845282+0.j  1.85350016+0.j]\n",
            " [-1.57472574+0.j  1.7867524 +0.j]\n",
            " [-1.62416259+0.j  2.28016566+0.j]\n",
            " [-0.90559708+0.j  1.55384878+0.j]\n",
            " [-1.3646697 +0.j  1.79066333+0.j]\n",
            " [-1.41227097+0.j  1.91272532+0.j]\n",
            " [-1.09812247+0.j  1.21906561+0.j]\n",
            " [-1.41072422+0.j  2.10532293+0.j]\n",
            " [-1.09884217+0.j  1.22048477+0.j]\n",
            " [-1.63711422+0.j  1.86728257+0.j]\n",
            " [-0.99227354+0.j  2.02393488+0.j]\n",
            " [-1.2275123 +0.j  2.03219941+0.j]\n",
            " [-1.69105013+0.j  2.07002079+0.j]\n",
            " [-1.10795409+0.j  1.58188321+0.j]\n",
            " [-1.70233303+0.j  1.44752398+0.j]\n",
            " [-1.1450452 +0.j  1.54685021+0.j]\n",
            " [-1.95759003+0.j  2.34279489+0.j]\n",
            " [-1.13561707+0.j  1.85136919+0.j]\n",
            " [-1.86813628+0.j  1.59198658+0.j]\n",
            " [-1.52640477+0.j  1.66327126+0.j]\n",
            " [-1.22484967+0.j  1.85486491+0.j]\n",
            " [-1.27809972+0.j  1.96450211+0.j]\n",
            " [-1.52823302+0.j  1.7357989 +0.j]\n",
            " [-1.84183684+0.j  2.04923982+0.j]\n",
            " [-1.60113166+0.j  1.97342405+0.j]\n",
            " [-0.76649676+0.j  1.61946951+0.j]\n",
            " [-1.13029183+0.j  1.49670018+0.j]\n",
            " [-0.99835319+0.j  1.44898038+0.j]\n",
            " [-1.11046821+0.j  1.74751187+0.j]\n",
            " [-2.10474676+0.j  1.78645315+0.j]\n",
            " [-1.74725248+0.j  2.08158057+0.j]\n",
            " [-1.55529829+0.j  2.40607704+0.j]\n",
            " [-1.49013252+0.j  2.04482468+0.j]\n",
            " [-1.45320911+0.j  1.40223442+0.j]\n",
            " [-1.29649126+0.j  2.00967573+0.j]\n",
            " [-1.37168287+0.j  1.66561696+0.j]\n",
            " [-1.54396194+0.j  1.60363801+0.j]\n",
            " [-1.54928719+0.j  1.95830702+0.j]\n",
            " [-1.19829525+0.j  1.65648742+0.j]\n",
            " [-0.89998215+0.j  1.4745917 +0.j]\n",
            " [-1.42929079+0.j  1.77169691+0.j]\n",
            " [-1.26713303+0.j  1.92108151+0.j]\n",
            " [-1.35621712+0.j  1.91287139+0.j]\n",
            " [-1.28105203+0.j  1.86642468+0.j]\n",
            " [-0.69748396+0.j  1.73367505+0.j]\n",
            " [-1.31336257+0.j  1.85694147+0.j]\n",
            " [-3.07297353+0.j  2.63945476+0.j]\n",
            " [-2.36074266+0.j  1.99381411+0.j]\n",
            " [-2.58389066+0.j  2.12926312+0.j]\n",
            " [-2.4353704 +0.j  1.95886565+0.j]\n",
            " [-2.75375478+0.j  2.24675678+0.j]\n",
            " [-2.90077032+0.j  1.97753281+0.j]\n",
            " [-2.13338529+0.j  1.8736282 +0.j]\n",
            " [-2.61174417+0.j  1.7782359 +0.j]\n",
            " [-2.54359225+0.j  1.60674282+0.j]\n",
            " [-2.81794499+0.j  2.79032006+0.j]\n",
            " [-2.11820104+0.j  2.38600789+0.j]\n",
            " [-2.32281718+0.j  1.92404025+0.j]\n",
            " [-2.40683102+0.j  2.21679185+0.j]\n",
            " [-2.43507338+0.j  1.93545396+0.j]\n",
            " [-2.67124566+0.j  2.39362661+0.j]\n",
            " [-2.47677735+0.j  2.55249443+0.j]\n",
            " [-2.291341  +0.j  2.03833032+0.j]\n",
            " [-2.82471782+0.j  2.6072902 +0.j]\n",
            " [-3.2918322 +0.j  1.75573651+0.j]\n",
            " [-2.08523934+0.j  1.37134742+0.j]\n",
            " [-2.59763464+0.j  2.45340592+0.j]\n",
            " [-2.33037503+0.j  2.17921267+0.j]\n",
            " [-2.91638458+0.j  1.74198422+0.j]\n",
            " [-2.02295734+0.j  1.93474214+0.j]\n",
            " [-2.49815505+0.j  2.40790876+0.j]\n",
            " [-2.37636424+0.j  2.05708914+0.j]\n",
            " [-1.96323148+0.j  2.03154648+0.j]\n",
            " [-2.01170096+0.j  2.16673347+0.j]\n",
            " [-2.62954901+0.j  2.07540976+0.j]\n",
            " [-2.15745944+0.j  1.81469518+0.j]\n",
            " [-2.54204551+0.j  1.79934042+0.j]\n",
            " [-2.4392974 +0.j  2.5178381 +0.j]\n",
            " [-2.69614686+0.j  2.14067683+0.j]\n",
            " [-1.93135913+0.j  1.7773236 +0.j]\n",
            " [-2.29264009+0.j  1.48892561+0.j]\n",
            " [-2.67916088+0.j  2.19002338+0.j]\n",
            " [-2.72252626+0.j  2.71785395+0.j]\n",
            " [-2.29695594+0.j  2.1175874 +0.j]\n",
            " [-1.97446134+0.j  2.19006063+0.j]\n",
            " [-2.29090281+0.j  2.30203641+0.j]\n",
            " [-2.67758029+0.j  2.47430285+0.j]\n",
            " [-2.22807613+0.j  2.48521234+0.j]\n",
            " [-2.36074266+0.j  1.99381411+0.j]\n",
            " [-2.7564174 +0.j  2.42409128+0.j]\n",
            " [-2.76454644+0.j  2.66897701+0.j]\n",
            " [-2.37210552+0.j  2.40574766+0.j]\n",
            " [-2.19986847+0.j  1.83550757+0.j]\n",
            " [-2.22851433+0.j  2.22150625+0.j]\n",
            " [-2.55334801+0.j  2.69346131+0.j]\n",
            " [-2.1985849 +0.j  2.14319872+0.j]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nOBazNFKiIDa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Q2:Generative methods vs Discriminative methods"
      ]
    },
    {
      "metadata": {
        "id": "8at_JfzIiNAI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1-Logistic regression classifier"
      ]
    },
    {
      "metadata": {
        "id": "z02n2RubibS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_breast_cancer = pd.read_csv(\"breast-cancer-wisconsin.data.txt\", header=None)\n",
        "df_breast_cancer.replace('?',np.nan, inplace=True)\n",
        "\n",
        "df_breast_cancer.isnull().any(axis=1)\n",
        "df_breast_cancer.dropna(axis=0, inplace=True)\n",
        "df_breast_cancer.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdFc6OJL-TnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X = df_breast_cancer[[1,2,3,4,5,6,7,8,9]]\n",
        "# y = df_breast_cancer[10]\n",
        "df_breast_cancer = df_breast_cancer[[1,2,3,4,5,6,7,8,9,10]]\n",
        "print(df_breast_cancer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmmqfXXRBBPG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to predict for new data points\n",
        "# def predict(data, coeffs):\n",
        "# \tf = coeffs[0]\n",
        "#   print(data)\n",
        "# \tfor i in range(len(data)-1):\n",
        "# \t\tf += coeffs[i + 1] * data[i]\n",
        "# \treturn 1.0 / (1.0 + exp(-f))\n",
        "\n",
        "def predict(data, coeffs):\n",
        "  f = coeffs[0]\n",
        "#   print(len(data))\n",
        "#   print(data)\n",
        "  for i in range(len(data)-1):\n",
        "    f += coeffs[i+1] * int(data[i])\n",
        "  return 1.0 / (1.0 + exp(-f))\n",
        " \n",
        "# Stochastic Gradient Descent - finding coefficients\n",
        "# def SGD_coeffs(train, n_epoch, learning_rate):\n",
        "# \tcoef = [0.0 for i in range(len(train[0]))]\n",
        "# \tfor epoch in range(n_epoch):\n",
        "# \t\tfor data in train:      \n",
        "#       data = list(data)\n",
        "#       print(data)\n",
        "# \t\t\tf = predict(data, coef)\n",
        "# \t\t\terror = data[len(data)] - f\n",
        "# \t\t\tcoef[0] = coef[0] + learning_rate * error * f * (1.0 - f)\n",
        "# \t\t\tfor i in range(len(data)-1):\n",
        "# \t\t\t\tcoef[i + 1] = coef[i + 1] + learning_rate * error * f * (1.0 - f) * int(data[i+1])\n",
        "# \treturn coef\n",
        "\n",
        "def SGD_coeffs(train, n_epoch, learning_rate):\n",
        "  coef = [0.0 for i in range(len(train[0]))]\n",
        "  for epoch in range(n_epoch):\n",
        "    for data in train:\n",
        "      data = list(data.astype(int))\n",
        "#       print(data)\n",
        "      f = predict(data, coef)\n",
        "      error = data[-1] - f\n",
        "      coef[0] = coef[0] + learning_rate * error * f * (1.0 - f)\n",
        "      for i in range(len(data)-1):\n",
        "        coef[i + 1] = coef[i + 1] + learning_rate * error * f * (1.0 - f) * (data[i])\n",
        "  return coef\n",
        "  \n",
        "\n",
        "# MiniBatch Gradient Descent - finding coefficients\n",
        "def MBGD_coeffs(train, n_epoch, learning_rate):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor data in train:\n",
        "\t\t\tf = predict(data, coef)\n",
        "\t\t\terror = data[-1] - f\n",
        "\t\t\tcoef[0] = coef[0] + learning_rate * error * f * (1.0 - f)\n",
        "\t\t\tfor i in range(len(data)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] + learning_rate * error * f * (1.0 - f) * data[i+1]\n",
        "\treturn coef\n",
        " \n",
        "# Linear Regression Classifier using Stochastic Gradient Descent\n",
        "def logistic_regression_sgd(train, test, learning_rate, n_epoch):\n",
        "\tpredictions = []\n",
        "\tcoef = SGD_coeffs(train, n_epoch, learning_rate)\n",
        "\tfor data in test:\n",
        "\t\tf = predict(data, coef)\n",
        "\t\tf = round(f)\n",
        "\t\tpredictions.append(f)\n",
        "\treturn(predictions)\n",
        "\n",
        "# Linear Regression Classifier using MiniBatch Gradient Descent\n",
        "def logistic_regression_mbgd(train, test, learning_rate, n_epoch):\n",
        "\tpredictions = []\n",
        "\tcoef = MBGD_coefficients(train, n_epoch, learning_rate)\n",
        "\tfor data in test:\n",
        "\t\tf = predict(data, coef)\n",
        "\t\tf = round(f)\n",
        "\t\tpredictions.append(f)\n",
        "\treturn(predictions)\n",
        "\n",
        "########################################\n",
        "# Split a dataset into k folds\n",
        "# def cross_validation_split(dataset, n_folds):\n",
        "# \tdataset_split = list()\n",
        "# \tdataset_copy = list(dataset)\n",
        "# \tfold_size = int(len(dataset) / n_folds)\n",
        "# \tfor i in range(n_folds):\n",
        "# \t\tfold = list()\n",
        "# \t\twhile len(fold) < fold_size:\n",
        "# \t\t\tindex = randrange(len(dataset_copy))\n",
        "# \t\t\tfold.append(dataset_copy.pop(index))\n",
        "# \t\tdataset_split.append(fold)\n",
        "# \treturn dataset_split\n",
        "\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "  dataset_split = []\n",
        "  dataset_copy = dataset.copy()\n",
        "#   print(dataset_copy.shape[0])\n",
        "  fold_size = int(dataset.shape[0] / n_folds)\n",
        "#   print(fold_size)\n",
        "  for i in range(n_folds):\n",
        "    fold = []\n",
        "    while len(fold) < fold_size:\n",
        "#       print(\"fold:%d\"%len(fold))\n",
        "#       print(\"dataset_len:%d\"%(dataset_copy.shape[0]))\n",
        "      index = randrange((dataset_copy.shape[0]))\n",
        "      fold.append(dataset_copy.iloc[index])\n",
        "      dataset_copy.drop(index = [index])      \n",
        "    dataset_split.append(fold)\n",
        "  return dataset_split\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "# def accuracy_metric(actual, predicted):\n",
        "# \tcorrect = 0\n",
        "# \tfor i in range(len(actual)):\n",
        "# \t\tif actual[i] == predicted[i]:\n",
        "# \t\t\tcorrect += 1\n",
        "# \treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "  print(predicted)\n",
        "  correct = 0\n",
        "  for i in range(len(actual)):\n",
        "    if actual[i] == predicted[i]:\n",
        "      correct += 1\n",
        "  return correct / float(len(actual)) * 100.0\n",
        "\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "# def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "# \tfolds = cross_validation_split(dataset, n_folds)\n",
        "# \tscores = list()\n",
        "# \tfor fold in folds:\n",
        "# \t\ttrain_set = list(folds)\n",
        "# \t\ttrain_set.remove(fold)\n",
        "# \t\ttrain_set = sum(train_set, [])\n",
        "# \t\ttest_set = list()\n",
        "# \t\tfor row in fold:\n",
        "# \t\t\trow_copy = list(row)\n",
        "# \t\t\ttest_set.append(row_copy)\n",
        "# # \t\t\trow_copy[-1] = None\n",
        "#       actual.append(row_copy[-1])\n",
        "# \t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "# # \t\tactual = [row[-1] for row in fold]\n",
        "# \t\taccuracy = accuracy_metric(actual, predicted)\n",
        "# \t\tscores.append(accuracy)\n",
        "# \treturn scores\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "  folds = cross_validation_split(dataset, n_folds)\n",
        "  scores = list()\n",
        "  for fold in folds:\n",
        "    train_set = list(folds)\n",
        "    \n",
        "    try:\n",
        "        train_set.remove(fold)\n",
        "    except ValueError:\n",
        "        pass\n",
        "    \n",
        "    train_set = sum(train_set, [])\n",
        "    test_set = list()\n",
        "    actual = []\n",
        "    for row in fold:\n",
        "      row_copy = list(row)\n",
        "      test_set.append(row_copy)\n",
        "      actual.append(row_copy[-1])\n",
        "    predicted = algorithm(train_set, test_set, *args)\n",
        "    accuracy = accuracy_metric(actual, predicted)\n",
        "    scores.append(accuracy)\n",
        "  \n",
        "  return scores\n",
        "  \n",
        "  \n",
        "scores = evaluate_algorithm(df_breast_cancer, logistic_regression_sgd, 5, 0.1, 100)\n",
        "print('Scores: %s' % scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fgxKFBjw-m4s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "cf3f6d14-8780-4218-ca27-6371c659d95c"
      },
      "cell_type": "code",
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "# def accuracy_metric(actual, predicted):\n",
        "#   correct = 0\n",
        "#   print(predicted)\n",
        "#   for i in range(len(actual)):\n",
        "# \t\tif actual[i] == predicted[i]:\n",
        "# \t\t\tcorrect += 1\n",
        "# \treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "def accuracy_metric(actual, predicted):\n",
        "  correct = 0\n",
        "  print(predicted)\n",
        "  for i in range(len(actual)):\n",
        "    if actual[i] == predicted[i]:\n",
        "      correct += 1\n",
        "  return correct / float(len(actual)) * 100.0\n",
        " \n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\treturn scores\n",
        " \n",
        "# Make a prediction with coefficients\n",
        "def predict(row, coefficients):\n",
        "\tyhat = coefficients[0]\n",
        "\tfor i in range(len(row)-1):\n",
        "\t\tyhat += coefficients[i + 1] * int(row[i])\n",
        "\treturn 1.0 / (1.0 + exp(-yhat))\n",
        " \n",
        "# Estimate logistic regression coefficients using stochastic gradient descent\n",
        "def coefficients_sgd(train, l_rate, n_epoch):\n",
        "\tcoef = [0.0 for i in range(len(train[0]))]\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor row in train:\n",
        "\t\t\tyhat = predict(row, coef)\n",
        "\t\t\terror = row[-1] - yhat\n",
        "\t\t\tcoef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)\n",
        "\t\t\tfor i in range(len(row)-1):\n",
        "\t\t\t\tcoef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * int(row[i])\n",
        "\treturn coef\n",
        " \n",
        "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
        "def logistic_regression(train, test, l_rate, n_epoch):\n",
        "\tpredictions = list()\n",
        "\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n",
        "\tfor row in test:\n",
        "\t\tyhat = predict(row, coef)\n",
        "\t\tyhat = round(yhat)\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn(predictions)\n",
        "\n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column])\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tfor i in range(len(dataset[0])):\n",
        "\t\tcol_values = [row[i] for row in dataset]\n",
        "\t\tvalue_min = min(col_values)\n",
        "\t\tvalue_max = max(col_values)\n",
        "\t\tminmax.append([value_min, value_max])\n",
        "\treturn minmax\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "\n",
        "dataset = df_breast_cancer.values.tolist()\n",
        "for i in range(len(dataset[0])):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# normalize\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "l_rate = 0.1\n",
        "n_epoch = 100\n",
        "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0]\n",
            "[1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
            "[0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
            "[1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "Scores: [95.58823529411765, 93.38235294117648, 95.58823529411765, 92.64705882352942, 91.17647058823529]\n",
            "Mean Accuracy: 93.676%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GYd8BXhMiRG8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2-probabilistic generative model"
      ]
    },
    {
      "metadata": {
        "id": "oKIdd1Q3mJEJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3x10zvQZmLCz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}