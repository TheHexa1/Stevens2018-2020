{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_text.json'\n",
    "test_file = 'test_text.json'\n",
    "\n",
    "def load_json_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def prepare_df(train_df, test_df):       \n",
    "    \n",
    "    train_df = pd.DataFrame(load_json_file(train_file), columns=['text'])\n",
    "    \n",
    "    test_df = pd.DataFrame(load_json_file(test_file), columns=['text', 'labels'])\n",
    "    test_df['single_label'] = test_df['labels'].apply(lambda x: x[0])    \n",
    "    \n",
    "    return train_df, test_df    \n",
    "    \n",
    "    \n",
    "# def map_labels_and_print_outcomes():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3421, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train, columns=['text'])\n",
    "test_df = pd.DataFrame(test, columns=['text', 'labels'])\n",
    "\n",
    "test_df['single_label'] = test_df['labels'].apply(lambda x: x[0])\n",
    "train_df.shape\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3421, 18819)\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 3\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words=\"english\", min_df=3) \n",
    "\n",
    "tfidf= tfidf_vect.fit_transform(train_df['text'])\n",
    "print (tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 2, 0, 2, 1, 2, 1, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_clf = KMeansClusterer(n_clusters, cosine_distance, repeats=15)\n",
    "\n",
    "clusters = cluster_clf.cluster(tfidf.toarray(), assign_clusters=True)\n",
    "\n",
    "clusters[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 18819)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 2, 2, 0, 2, 1, 0, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf = tfidf_vect.transform(test_df['text'])\n",
    "print(test_tfidf.shape)\n",
    "\n",
    "preds = [cluster_clf.classify(doc) for doc in test_tfidf.toarray()]\n",
    "\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>single_label</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faa issues fire warning for lithium batteries ...</td>\n",
       "      <td>[Travel &amp; Transportation]</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraglider collides with hot air balloon in ar...</td>\n",
       "      <td>[Disaster and Accident, Travel &amp; Transportation]</td>\n",
       "      <td>Disaster and Accident</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rescuers pull from flooded coal mine in chinab...</td>\n",
       "      <td>[Disaster and Accident]</td>\n",
       "      <td>Disaster and Accident</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>japan factory output slides for fifth month in...</td>\n",
       "      <td>[News and Economy]</td>\n",
       "      <td>News and Economy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama signs emergency bill to halt teacher lay...</td>\n",
       "      <td>[News and Economy]</td>\n",
       "      <td>News and Economy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  faa issues fire warning for lithium batteries ...   \n",
       "1  paraglider collides with hot air balloon in ar...   \n",
       "2  rescuers pull from flooded coal mine in chinab...   \n",
       "3  japan factory output slides for fifth month in...   \n",
       "4  obama signs emergency bill to halt teacher lay...   \n",
       "\n",
       "                                             labels             single_label  \\\n",
       "0                         [Travel & Transportation]  Travel & Transportation   \n",
       "1  [Disaster and Accident, Travel & Transportation]    Disaster and Accident   \n",
       "2                           [Disaster and Accident]    Disaster and Accident   \n",
       "3                                [News and Economy]         News and Economy   \n",
       "4                                [News and Economy]         News and Economy   \n",
       "\n",
       "   cluster_id  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-3f5f811b4637>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# cluster and ground_truth label mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m cluster_dict = {0: list(nltk.FreqDist(cluster_0).keys())[0],\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 2: list(nltk.FreqDist(cluster_2).keys())[0]}\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_df['cluster_id'] = preds\n",
    "\n",
    "cluster_0 = test_df['single_label'][test_df.cluster_id==0]\n",
    "cluster_1 = test_df['single_label'][test_df.cluster_id==1]\n",
    "cluster_2 = test_df['single_label'][test_df.cluster_id==2]\n",
    "\n",
    "# list(nltk.FreqDist(cluster_0).keys())[0]\n",
    "# nltk.FreqDist(cluster_1)\n",
    "# nltk.FreqDist(cluster_2)\n",
    "\n",
    "# cluster and ground_truth label mapping\n",
    "cluster_dict = {0: list(nltk.FreqDist(cluster_0).keys())[0],\n",
    "                1: list(nltk.FreqDist(cluster_1).keys())[0],\n",
    "                2: list(nltk.FreqDist(cluster_2).keys())[0]}\n",
    "\n",
    "# Map true label to cluster id\n",
    "preds_label = [cluster_dict[i] for i in preds]\n",
    "\n",
    "confusion_df = pd.DataFrame(list(zip(test_df[\"single_label\"].values, preds)),\\\n",
    "                            columns = [\"actual class\", \"cluster\"])\n",
    "\n",
    "print(pd.crosstab(index=confusion_df.cluster, columns=confusion_df['actual class']))\n",
    "\n",
    "print('Cluster 0: Topic',cluster_dict[0])\n",
    "print('Cluster 1: Topic',cluster_dict[1])\n",
    "print('Cluster 2: Topic',cluster_dict[2])\n",
    "\n",
    "\n",
    "print(metrics.classification_report(test_df[\"single_label\"], preds_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train_file, test_file):\n",
    "    \n",
    "    # dataset preparation\n",
    "    train_df, test_df = prepare_df(train_file, test_file)    \n",
    "\n",
    "    # parameters\n",
    "    n_clusters = 3\n",
    "    MIN_DF = 3\n",
    "    STOP_WORDS = 'english'\n",
    "    EPOCHS = 20\n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(stop_words=STOP_WORDS, min_df=MIN_DF) \n",
    "    tfidf= tfidf_vect.fit_transform(train_df['text'])\n",
    "\n",
    "    cluster_clf = KMeansClusterer(n_clusters, cosine_distance, repeats=EPOCHS)\n",
    "    clusters = cluster_clf.cluster(tfidf.toarray(), assign_clusters=True)\n",
    "\n",
    "    test_tfidf = tfidf_vect.transform(test_df['text'])\n",
    "\n",
    "    preds = [cluster_clf.classify(doc) for doc in test_tfidf.toarray()]\n",
    "\n",
    "    test_df['cluster_id'] = preds\n",
    "\n",
    "    # extract ground_truth labels for each cluter\n",
    "    cluster_0 = test_df['single_label'][test_df.cluster_id==0]\n",
    "    cluster_1 = test_df['single_label'][test_df.cluster_id==1]\n",
    "    cluster_2 = test_df['single_label'][test_df.cluster_id==2]\n",
    "\n",
    "    # cluster and ground_truth label mapping\n",
    "    cluster_dict = {0: list(nltk.FreqDist(cluster_0).keys())[0],\n",
    "                    1: list(nltk.FreqDist(cluster_1).keys())[0],\n",
    "                    2: list(nltk.FreqDist(cluster_2).keys())[0]}\n",
    "\n",
    "    # Map true label to cluster id\n",
    "    preds_label = [cluster_dict[i] for i in preds]\n",
    "\n",
    "    # confusion matrix/table\n",
    "    confusion_df = pd.DataFrame(list(zip(test_df[\"single_label\"].values, preds)),\\\n",
    "                                columns = [\"actual class\", \"cluster\"])    \n",
    "    print(pd.crosstab(index=confusion_df.cluster, columns=confusion_df['actual class']))\n",
    "\n",
    "    # cluster and topic assigned to it\n",
    "    print('Cluster 0: Topic',cluster_dict[0])\n",
    "    print('Cluster 1: Topic',cluster_dict[1])\n",
    "    print('Cluster 2: Topic',cluster_dict[2])\n",
    "\n",
    "    # evaluation metrics\n",
    "    print(metrics.classification_report(test_df[\"single_label\"], preds_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mabus to hold town hall meetings on gulf s fut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flood waters swamp guthrie s hwy erin guy shot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>express trains collide in fog bound northern i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new home sales up but sales remain slowwashing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>itv com contains the following categories ther...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  mabus to hold town hall meetings on gulf s fut...\n",
       "1  flood waters swamp guthrie s hwy erin guy shot...\n",
       "2  express trains collide in fog bound northern i...\n",
       "3  new home sales up but sales remain slowwashing...\n",
       "4  itv com contains the following categories ther..."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 25, perplexity: 4250.5376\n",
      "iteration: 2 of max_iter: 25, perplexity: 3801.0843\n",
      "iteration: 3 of max_iter: 25, perplexity: 3609.7047\n",
      "iteration: 4 of max_iter: 25, perplexity: 3530.5465\n",
      "iteration: 5 of max_iter: 25, perplexity: 3494.8408\n",
      "iteration: 6 of max_iter: 25, perplexity: 3473.0364\n",
      "iteration: 7 of max_iter: 25, perplexity: 3454.9284\n",
      "iteration: 8 of max_iter: 25, perplexity: 3439.2839\n",
      "iteration: 9 of max_iter: 25, perplexity: 3426.7504\n",
      "iteration: 10 of max_iter: 25, perplexity: 3416.5917\n",
      "iteration: 11 of max_iter: 25, perplexity: 3409.4712\n",
      "iteration: 12 of max_iter: 25, perplexity: 3403.4632\n",
      "iteration: 13 of max_iter: 25, perplexity: 3396.3725\n",
      "iteration: 14 of max_iter: 25, perplexity: 3387.7223\n",
      "iteration: 15 of max_iter: 25, perplexity: 3382.7160\n",
      "iteration: 16 of max_iter: 25, perplexity: 3380.7555\n",
      "iteration: 17 of max_iter: 25, perplexity: 3379.6781\n",
      "iteration: 18 of max_iter: 25, perplexity: 3378.8929\n",
      "iteration: 19 of max_iter: 25, perplexity: 3378.2673\n",
      "iteration: 20 of max_iter: 25, perplexity: 3377.7126\n",
      "iteration: 21 of max_iter: 25, perplexity: 3377.2467\n",
      "iteration: 22 of max_iter: 25, perplexity: 3376.8807\n",
      "iteration: 23 of max_iter: 25, perplexity: 3376.5611\n",
      "iteration: 24 of max_iter: 25, perplexity: 3376.2621\n",
      "iteration: 25 of max_iter: 25, perplexity: 3375.9923\n"
     ]
    }
   ],
   "source": [
    "# dataset preparation\n",
    "train_df, test_df = prepare_df(train_file, test_file)\n",
    "\n",
    "n_topics = 3\n",
    "MIN_DF = 5\n",
    "MAX_DF = 0.9\n",
    "STOP_WORDS = 'english'\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=MAX_DF, min_df=MIN_DF, stop_words=STOP_WORDS)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=25, verbose=1, evaluate_every=1, n_jobs=1,\n",
    "                                random_state=0).fit(tf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                30                18                      138\n",
      "1                                12               182                        8\n",
      "2                               168                 6                       38\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic News and Economy\n",
      "Cluster 2: Topic Disaster and Accident\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.79      0.80      0.80       210\n",
      "       News and Economy       0.90      0.88      0.89       206\n",
      "Travel & Transportation       0.74      0.75      0.75       184\n",
      "\n",
      "              micro avg       0.81      0.81      0.81       600\n",
      "              macro avg       0.81      0.81      0.81       600\n",
      "           weighted avg       0.81      0.81      0.81       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_test = tf_vectorizer.transform(test_df['text'])\n",
    "topic_assign=lda.transform(tf_test)\n",
    "\n",
    "topic_assign\n",
    "preds = np.argmax(topic_assign, axis=1)\n",
    "\n",
    "test_df['cluster_id'] = preds\n",
    "\n",
    "# extract ground_truth labels for each cluter\n",
    "cluster_0 = test_df['single_label'][test_df.cluster_id==0]\n",
    "cluster_1 = test_df['single_label'][test_df.cluster_id==1]\n",
    "cluster_2 = test_df['single_label'][test_df.cluster_id==2]\n",
    "\n",
    "# cluster and ground_truth label mapping\n",
    "cluster_dict = {0: list(nltk.FreqDist(cluster_0).keys())[0],\n",
    "                1: list(nltk.FreqDist(cluster_1).keys())[0],\n",
    "                2: list(nltk.FreqDist(cluster_2).keys())[0]}\n",
    "\n",
    "# Map true label to cluster id\n",
    "preds_label = [cluster_dict[i] for i in preds]\n",
    "\n",
    "\n",
    "# confusion matrix/table\n",
    "confusion_df = pd.DataFrame(list(zip(test_df[\"single_label\"].values, preds)),\\\n",
    "                            columns = [\"actual class\", \"cluster\"])    \n",
    "print(pd.crosstab(index=confusion_df.cluster, columns=confusion_df['actual class']))\n",
    "\n",
    "# cluster and topic assigned to it\n",
    "print('Cluster 0: Topic',cluster_dict[0])\n",
    "print('Cluster 1: Topic',cluster_dict[1])\n",
    "print('Cluster 2: Topic',cluster_dict[2])\n",
    "\n",
    "# evaluation metrics\n",
    "print(metrics.classification_report(test_df[\"single_label\"], preds_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 3)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_assign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train_file, test_file):\n",
    "    topic_assig = None\n",
    "    labels = None\n",
    "    \n",
    "    # dataset preparation\n",
    "    train_df, test_df = prepare_df(train_file, test_file)\n",
    "    \n",
    "    labels = test_df['labels']\n",
    "\n",
    "    n_topics = 3\n",
    "    MIN_DF = 5\n",
    "    MAX_DF = 0.9\n",
    "    STOP_WORDS = 'english'\n",
    "\n",
    "    tf_vectorizer = CountVectorizer(max_df=MAX_DF, min_df=MIN_DF, stop_words=STOP_WORDS)\n",
    "\n",
    "    tf = tf_vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=25, verbose=1, evaluate_every=1, n_jobs=1,\n",
    "                                    random_state=0).fit(tf)\n",
    "\n",
    "    tf_test = tf_vectorizer.transform(test_df['text'])\n",
    "    topic_assig=lda.transform(tf_test)\n",
    "    \n",
    "    preds = np.argmax(topic_assig, axis=1)\n",
    "\n",
    "    test_df['cluster_id'] = preds\n",
    "\n",
    "    # extract ground_truth labels for each cluter\n",
    "    cluster_0 = test_df['single_label'][test_df.cluster_id==0]\n",
    "    cluster_1 = test_df['single_label'][test_df.cluster_id==1]\n",
    "    cluster_2 = test_df['single_label'][test_df.cluster_id==2]\n",
    "\n",
    "    # cluster and ground_truth label mapping\n",
    "    cluster_dict = {0: list(nltk.FreqDist(cluster_0).keys())[0],\n",
    "                    1: list(nltk.FreqDist(cluster_1).keys())[0],\n",
    "                    2: list(nltk.FreqDist(cluster_2).keys())[0]}\n",
    "\n",
    "    # Map true label to cluster id\n",
    "    preds_label = [cluster_dict[i] for i in preds]\n",
    "\n",
    "    # confusion matrix/table\n",
    "    confusion_df = pd.DataFrame(list(zip(test_df[\"single_label\"].values, preds)),\\\n",
    "                                columns = [\"actual class\", \"cluster\"])    \n",
    "    print(pd.crosstab(index=confusion_df.cluster, columns=confusion_df['actual class']))\n",
    "\n",
    "    # cluster and topic assigned to it\n",
    "    print('Cluster 0: Topic',cluster_dict[0])\n",
    "    print('Cluster 1: Topic',cluster_dict[1])\n",
    "    print('Cluster 2: Topic',cluster_dict[2])\n",
    "\n",
    "    # evaluation metrics\n",
    "    print(metrics.classification_report(test_df[\"single_label\"], preds_label))\n",
    "    \n",
    "    return topic_assign, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63987687, 0.00139012, 0.358733  ],\n",
       "       [0.0072369 , 0.00566312, 0.98709997],\n",
       "       [0.01754705, 0.03554542, 0.94690754],\n",
       "       ...,\n",
       "       [0.07718694, 0.39525681, 0.52755625],\n",
       "       [0.04108562, 0.95689438, 0.00202   ],\n",
       "       [0.1435063 , 0.56214291, 0.29435079]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>single_label</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>combined_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faa issues fire warning for lithium batteries ...</td>\n",
       "      <td>[Travel &amp; Transportation]</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paraglider collides with hot air balloon in ar...</td>\n",
       "      <td>[Disaster and Accident, Travel &amp; Transportation]</td>\n",
       "      <td>Disaster and Accident</td>\n",
       "      <td>2</td>\n",
       "      <td>Disaster and Accident_Travel &amp; Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rescuers pull from flooded coal mine in chinab...</td>\n",
       "      <td>[Disaster and Accident]</td>\n",
       "      <td>Disaster and Accident</td>\n",
       "      <td>2</td>\n",
       "      <td>Disaster and Accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>japan factory output slides for fifth month in...</td>\n",
       "      <td>[News and Economy]</td>\n",
       "      <td>News and Economy</td>\n",
       "      <td>1</td>\n",
       "      <td>News and Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama signs emergency bill to halt teacher lay...</td>\n",
       "      <td>[News and Economy]</td>\n",
       "      <td>News and Economy</td>\n",
       "      <td>1</td>\n",
       "      <td>News and Economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  faa issues fire warning for lithium batteries ...   \n",
       "1  paraglider collides with hot air balloon in ar...   \n",
       "2  rescuers pull from flooded coal mine in chinab...   \n",
       "3  japan factory output slides for fifth month in...   \n",
       "4  obama signs emergency bill to halt teacher lay...   \n",
       "\n",
       "                                             labels             single_label  \\\n",
       "0                         [Travel & Transportation]  Travel & Transportation   \n",
       "1  [Disaster and Accident, Travel & Transportation]    Disaster and Accident   \n",
       "2                           [Disaster and Accident]    Disaster and Accident   \n",
       "3                                [News and Economy]         News and Economy   \n",
       "4                                [News and Economy]         News and Economy   \n",
       "\n",
       "  cluster_id                                combined_labels  \n",
       "0          0                        Travel & Transportation  \n",
       "1          2  Disaster and Accident_Travel & Transportation  \n",
       "2          2                          Disaster and Accident  \n",
       "3          1                               News and Economy  \n",
       "4          1                               News and Economy  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_df['labels'].apply(lambda x: len(x))).count(3)\n",
    "test_df['combined_labels'] = test_df['labels'].apply(lambda x: \"_\".join(x))\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel & Transportation:  0.7459459459459459\n",
      "Disaster and Accident:  0.7962085308056872\n",
      "News and Economy:  0.8938271604938272\n",
      "\n",
      "Travel & Transportation:  0.5\n",
      "Disaster and Accident:  0.5\n",
      "News and Economy:  0.45\n",
      "\n",
      "################# Extras: Displaying multilabel classification #######################\n",
      "Disaster and Accident_Travel & Transportation:  0.1724137931034483\n",
      "News and Economy_Travel & Transportation:  0.047619047619047616\n",
      "Disaster and Accident_Travel & Transportation:  0.2\n",
      "News and Economy_Travel & Transportation:  0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_labels</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.15000000000000002</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.35000000000000003</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.45</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.55</th>\n",
       "      <th>0.6000000000000001</th>\n",
       "      <th>0.6500000000000001</th>\n",
       "      <th>0.7000000000000001</th>\n",
       "      <th>0.7500000000000001</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.8500000000000001</th>\n",
       "      <th>0.9000000000000001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>News and Economy_Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "      <td>Travel &amp; Transportation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              combined_labels  \\\n",
       "452  News and Economy_Travel & Transportation   \n",
       "\n",
       "                                         0.05  \\\n",
       "452  News and Economy_Travel & Transportation   \n",
       "\n",
       "                                          0.1  \\\n",
       "452  News and Economy_Travel & Transportation   \n",
       "\n",
       "                          0.15000000000000002  \\\n",
       "452  News and Economy_Travel & Transportation   \n",
       "\n",
       "                                          0.2  \\\n",
       "452  News and Economy_Travel & Transportation   \n",
       "\n",
       "                                         0.25  \\\n",
       "452  News and Economy_Travel & Transportation   \n",
       "\n",
       "                                          0.3      0.35000000000000003  \\\n",
       "452  News and Economy_Travel & Transportation  Travel & Transportation   \n",
       "\n",
       "                         0.4                     0.45  \\\n",
       "452  Travel & Transportation  Travel & Transportation   \n",
       "\n",
       "                         0.5                     0.55  \\\n",
       "452  Travel & Transportation  Travel & Transportation   \n",
       "\n",
       "          0.6000000000000001       0.6500000000000001  \\\n",
       "452  Travel & Transportation  Travel & Transportation   \n",
       "\n",
       "          0.7000000000000001       0.7500000000000001  \\\n",
       "452  Travel & Transportation  Travel & Transportation   \n",
       "\n",
       "                         0.8       0.8500000000000001       0.9000000000000001  \n",
       "452  Travel & Transportation  Travel & Transportation  Travel & Transportation  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = test_df['labels']\n",
    "labels = list(set(test_df['combined_labels']))\n",
    "f1_score_l1 = [] #Travel&Transportation\n",
    "f1_score_l2 = [] #Disaster and Accident\n",
    "f1_score_l3 = [] #News and Economy\n",
    "f1_score_l4 = [] #Disaster and Accident_Travel & Transportation\n",
    "f1_score_l5 = [] #News and Economy_Travel & Transportation\n",
    "threshold = []\n",
    "prediction_df = pd.DataFrame(data=test_df['combined_labels'])\n",
    "\n",
    "\n",
    "for t in arange(0.05, 0.95, 0.05):\n",
    "    \n",
    "    preds = []\n",
    "    preds_label = []\n",
    "    threshold.append(t)\n",
    "#     print(i)\n",
    "    for row in range(topic_assign.shape[0]):        \n",
    "        labels_ = \"\"        \n",
    "        for topic in range(3):\n",
    "            if topic_assign[row][topic] > t:\n",
    "                labels_ += str(topic)            \n",
    "        \n",
    "        if labels_ == \"\":\n",
    "            preds.append(str(np.argmax(topic_assign[row])))\n",
    "        else:\n",
    "            preds.append(labels_)\n",
    "    \n",
    "#     print(preds)\n",
    "    \n",
    "    test_df['cluster_id'] = preds\n",
    "\n",
    "#     print(test_df['cluster_id'])\n",
    "    # extract ground_truth labels for each cluter\n",
    "    \n",
    "    cluster_0 = []\n",
    "    cluster_01 = []\n",
    "    cluster_02 = []\n",
    "    cluster_1 = []\n",
    "    cluster_12 = []\n",
    "    cluster_2 = []\n",
    "    \n",
    "    for i, row in test_df['combined_labels'].items():\n",
    "#         print(row)\n",
    "        if '0' in test_df['cluster_id'][i]:\n",
    "#         if test_df['cluster_id'][i] == '0':\n",
    "            cluster_0.append((row))\n",
    "        if '1' in test_df['cluster_id'][i]:\n",
    "            cluster_1.append(row)\n",
    "        if '2' in test_df['cluster_id'][i]:\n",
    "#         if test_df['cluster_id'][i] == '01':\n",
    "            cluster_2.append((row))\n",
    "#         if test_df['cluster_id'][i] == '02':\n",
    "#             cluster_02.append((row))\n",
    "#         if test_df['cluster_id'][i] == '1':\n",
    "#             cluster_1.append((row))\n",
    "#         if test_df['cluster_id'][i] == '12':\n",
    "#             cluster_12.append((row))\n",
    "#         if test_df['cluster_id'][i] == '2':\n",
    "#             cluster_2.append((row))\n",
    "#         print('out')\n",
    "#         cluster_1 = test_df['labels'][1 in test_df.cluster_id]\n",
    "#         cluster_2 = test_df['labels'][2 in test_df.cluster_id]\n",
    "\n",
    "#     print((nltk.FreqDist(cluster_12).most_common()))\n",
    "    \n",
    "#     print(cluster_0)\n",
    "    # cluster and ground_truth label mapping\n",
    "    #'':'Travel & Transportation',\n",
    "    \n",
    "#     predicted_topics = list(set(preds))\n",
    "#     cluster_dict = {}\n",
    "#     for t in predicted_topics:\n",
    "#         if predicted_topics not in ['0', '1', '2']:\n",
    "#             cluster_dict[t] = nltk.FreqDist(cluster_0).most_common()[0][0]\n",
    "        \n",
    "        \n",
    "    cluster_dict = { \n",
    "                    '0': nltk.FreqDist(cluster_0).most_common()[0][0],\n",
    "                    '01': nltk.FreqDist(cluster_1).most_common()[0][0]+'_'+\n",
    "                            nltk.FreqDist(cluster_0).most_common()[0][0],\n",
    "                    '02': nltk.FreqDist(cluster_2).most_common()[0][0]+'_'+\n",
    "                            nltk.FreqDist(cluster_0).most_common()[0][0],\n",
    "                    '1':  nltk.FreqDist(cluster_1).most_common()[0][0],\n",
    "                    '12': nltk.FreqDist(cluster_2).most_common()[0][0]+'_'+\n",
    "                            nltk.FreqDist(cluster_1).most_common()[0][0],\n",
    "                    '2':  nltk.FreqDist(cluster_2).most_common()[0][0],\n",
    "                    '012': nltk.FreqDist(cluster_0).most_common()[0][0]+'_'+\n",
    "                            nltk.FreqDist(cluster_1).most_common()[0][0]+'_'+\n",
    "                            nltk.FreqDist(cluster_2).most_common()[0][0]}\n",
    "\n",
    "    \n",
    "#     print(dict(nltk.FreqDist(cluster_1)))\n",
    "#     print(dict(nltk.FreqDist(cluster_2)))\n",
    "    # Map true label to cluster id\n",
    "    \n",
    "    #preds_label = [cluster_dict[i] for i in preds]\n",
    "    for i in preds:\n",
    "#         if i in ['0', '1', '2']:\n",
    "        preds_label.append(cluster_dict[i])\n",
    "#         elif i == '01':\n",
    "#             preds_label.append(cluster_dict)\n",
    "    \n",
    "    prediction_df[t] = preds_label\n",
    "#     print(labels)\n",
    "    scores = f1_score(test_df['single_label'], preds_label, labels, average=None)\n",
    "    f1_score_l1.append(scores[2]) #travel\n",
    "    f1_score_l2.append(scores[3]) #disaster\n",
    "    f1_score_l3.append(scores[1]) #news\n",
    "    \n",
    "    combined_label_scores = f1_score(test_df['combined_labels'], preds_label, labels, average=None)\n",
    "    f1_score_l4.append(combined_label_scores[4]) #disaster_and_travel\n",
    "    f1_score_l5.append(combined_label_scores[0]) #newsand_travel\n",
    "    \n",
    "    \n",
    "print(labels[2]+': ',max(f1_score_l1))\n",
    "print(labels[3]+': ',max(f1_score_l2))\n",
    "print(labels[1]+': ',max(f1_score_l3))\n",
    "print(\"\")\n",
    "print(labels[2]+': ',threshold[np.argmax(f1_score_l1)])\n",
    "print(labels[3]+': ',threshold[np.argmax(f1_score_l2)])\n",
    "print(labels[1]+': ',threshold[np.argmax(f1_score_l3)])\n",
    "\n",
    "print(\"\")\n",
    "print(\"################# Extras: Displaying multilabel classification #######################\")\n",
    "print(labels[4]+': ',max(f1_score_l4))\n",
    "print(labels[0]+': ',max(f1_score_l5))\n",
    "print(labels[4]+': ',threshold[np.argmax(f1_score_l4)])\n",
    "print(labels[0]+': ',threshold[np.argmax(f1_score_l5)])\n",
    "\n",
    "prediction_df\n",
    "prediction_df[prediction_df['combined_labels']=='News and Economy_Travel & Transportation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_cluster(topic_assign, labels):\n",
    "    final_thresh, f1 = None, None\n",
    "    \n",
    "    df = pd.DataFrame(data=labels, columns=['labels'])\n",
    "    df['combined_labels'] = df['labels'].apply(lambda x: \"_\".join(x))\n",
    "    df['single_label'] = df['labels'].apply(lambda x: x[0])\n",
    "\n",
    "    unique_labels = list(set(df['combined_labels']))\n",
    "    f1_score_l1 = [] #Travel&Transportation\n",
    "    f1_score_l2 = [] #Disaster and Accident\n",
    "    f1_score_l3 = [] #News and Economy\n",
    "    f1_score_l4 = [] #Disaster and Accident_Travel & Transportation\n",
    "    f1_score_l5 = [] #News and Economy_Travel & Transportation\n",
    "    threshold = []\n",
    "    prediction_df = pd.DataFrame(data=df['combined_labels'])\n",
    "\n",
    "    for t in arange(0.05, 0.95, 0.05):\n",
    "        preds = []\n",
    "        preds_label = []\n",
    "        threshold.append(t)\n",
    "        for row in range(topic_assign.shape[0]):        \n",
    "            labels_ = \"\"        \n",
    "            for topic in range(3):\n",
    "                if topic_assign[row][topic] > t:\n",
    "                    labels_ += str(topic)            \n",
    "\n",
    "            if labels_ == \"\":\n",
    "                preds.append(str(np.argmax(topic_assign[row])))\n",
    "            else:\n",
    "                preds.append(labels_)\n",
    "\n",
    "        df['topic_id'] = preds\n",
    "\n",
    "        topic_0 = []\n",
    "        topic_01 = []\n",
    "        topic_02 = []\n",
    "        topic_1 = []\n",
    "        topic_12 = []\n",
    "        topic_2 = []\n",
    "\n",
    "        for i, row in df['combined_labels'].items():\n",
    "    \n",
    "            if '0' in df['topic_id'][i]:    \n",
    "                topic_0.append((row))\n",
    "            if '1' in df['topic_id'][i]:\n",
    "                topic_1.append(row)\n",
    "            if '2' in df['topic_id'][i]:   \n",
    "                topic_2.append((row))\n",
    "\n",
    "        topic_dict = { \n",
    "                        '0': nltk.FreqDist(topic_0).most_common()[0][0],\n",
    "                        '01': nltk.FreqDist(topic_1).most_common()[0][0]+'_'+\n",
    "                                nltk.FreqDist(topic_0).most_common()[0][0],\n",
    "                        '02': nltk.FreqDist(topic_2).most_common()[0][0]+'_'+\n",
    "                                nltk.FreqDist(topic_0).most_common()[0][0],\n",
    "                        '1':  nltk.FreqDist(topic_1).most_common()[0][0],\n",
    "                        '12': nltk.FreqDist(topic_2).most_common()[0][0]+'_'+\n",
    "                                nltk.FreqDist(topic_1).most_common()[0][0],\n",
    "                        '2':  nltk.FreqDist(topic_2).most_common()[0][0],\n",
    "                        '012': nltk.FreqDist(topic_0).most_common()[0][0]+'_'+\n",
    "                                nltk.FreqDist(topic_1).most_common()[0][0]+'_'+\n",
    "                                nltk.FreqDist(topic_2).most_common()[0][0]}\n",
    "        \n",
    "        for i in preds:\n",
    "            preds_label.append(topic_dict[i])\n",
    "\n",
    "        prediction_df[t] = preds_label\n",
    "        scores = f1_score(df['single_label'], preds_label, unique_labels, average=None)\n",
    "        f1_score_l1.append(scores[2]) #travel\n",
    "        f1_score_l2.append(scores[3]) #disaster\n",
    "        f1_score_l3.append(scores[1]) #news\n",
    "\n",
    "        combined_label_scores = f1_score(df['combined_labels'], preds_label, unique_labels, average=None)\n",
    "        f1_score_l4.append(combined_label_scores[4]) #disaster_and_travel\n",
    "        f1_score_l5.append(combined_label_scores[0]) #news_and_travel\n",
    "\n",
    "    print(labels[2]+': ',max(f1_score_l1))\n",
    "    print(labels[3]+': ',max(f1_score_l2))\n",
    "    print(labels[1]+': ',max(f1_score_l3))\n",
    "    print(\"\")\n",
    "    print(labels[2]+': ',threshold[np.argmax(f1_score_l1)])\n",
    "    print(labels[3]+': ',threshold[np.argmax(f1_score_l2)])\n",
    "    print(labels[1]+': ',threshold[np.argmax(f1_score_l3)])\n",
    "\n",
    "#     print(\"\")\n",
    "#     print(\"################# Uncomment to display multilabel classification #######################\")\n",
    "#     print(labels[4]+': ',max(f1_score_l4))\n",
    "#     print(labels[0]+': ',max(f1_score_l5))\n",
    "#     print(labels[4]+': ',threshold[np.argmax(f1_score_l4)])\n",
    "#     print(labels[0]+': ',threshold[np.argmax(f1_score_l5)])\n",
    "\n",
    "#     prediction_df[prediction_df['combined_labels']=='News and Economy_Travel & Transportation']\n",
    "#     prediction_df[prediction_df['combined_labels']=='Disaster and Accident_Travel & Transportation']\n",
    "    \n",
    "    return final_thresh, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Q1 ###\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Due to randomness, you won't get the exact result\n",
    "    # as shown here, but your result should be close\n",
    "    # if you tune the parameters carefully\n",
    "    print('### Q1 ###')\n",
    "    # Q1\n",
    "    cluster_kmean('train_text.json', 'test_text.json')\n",
    "    print(\"\\n### Q2 ###\")\n",
    "    # Q2\n",
    "    topic_assign, labels =cluster_lda('train_text.json', 'test_text.json')\n",
    "    print(\"\\n### Q3 ###\")\n",
    "    # Q2\n",
    "    threshold, f1 = overlapping_cluster(topic_assign, labels)\n",
    "#     print(threshold)\n",
    "#     print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
