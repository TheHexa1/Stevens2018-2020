{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to analyze a numpy array\n",
    " - Assume we have an array (with shape (M,N)) which contains term frequency of each document, where each row is a document, each column is a word, and the corresponding value denotes the frequency of the word in the document. Define a function named \"analyze_tf_idf\" which:\n",
    "      * takes the **array**, and an integer **K** as the parameters.\n",
    "      * normalizes the frequency of each word as: word frequency divided by the length of the document. Save the result as an array named **tf** (i.e. term frequency)\n",
    "      * calculates the document frequency (**df**) of each word, e.g. how many documents contain a specific word\n",
    "      * calculates **tf_idf** array as: **tf / (log(df)+1)** (tf divided by log(df)). The reason is, if a word appears in most documents, it does not have the discriminative power and often is called a \"stop\" word. The inverse of df can downgrade the weight of such words.\n",
    "      * for each document, finds out the **indexes of words with top K largest values in the tf_idf array**, ($0<K<=N$). These indexes form an array, say **top_K**, with shape (M, K)\n",
    "      * returns the tf_idf array, and the top_K array.\n",
    " - Note, for all the steps, ** do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to analyze stackoverflow dataset using pandas\n",
    " - Define a function named \"analyze_data\" to do the follows:\n",
    "   * Take a csv file path string as an input. Assume the csv file is in the format of the provided sample file (question.csv).\n",
    "   * Read the csv file as a dataframe with the first row as column names\n",
    "   * Find questions with top 3 viewcounts among those answered questions (i.e answercount>0). Print the title and viewcount columns of these questions.\n",
    "   * Find the top 5 users (i.e. quest_name) who asked the most questions.\n",
    "   * Create a new column called \"first_tag\" to store the very first tag in the \"tags\" column (hint: use \"apply\" function; tags are separted by \", \")\n",
    "   * Show the mean, min, and max viewcount values for each of these tags: \"python\", \"pandas\" and \"dataframe\"\n",
    "   * Create a cross tab with answercount as row indexes, first_tag as column names, and the count of samples as the value. For \"python\" question (i.e. first_tag=\"python\"), how many questions were not answered (i.e., answercount=0), how many questions were answered once (i.e., answercount=1), and how many questions were anasered twice  (i.e., answercount=2)? Print these numbers.\n",
    " - This function does not have any return. Just print out the result of each calculation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (Bonus). Analyzed a collection of documents\n",
    " - Define a function named \"analyze_corpus\" to do the follows:\n",
    "   * Similar to Q2, take a csv file path string as an input. Assume the csv file is in the format of the provided sample file (question.csv).\n",
    "   * Read the \"title\" column from the csv file and convert it to lower case\n",
    "   * Split each string in the \"title\" column by space to get tokens. Create an array where each row represents a title, each column denotes a unique token, and each value denotes the count of the token in the document\n",
    "   * Call your function in Q1 (i.e. analyze_tf_idf) to analyze this array\n",
    "   * Print out the top 5 words by tf-idf score for the first 20 questions. Do you think these top words allow you to find similar questions or differentiate a question from dissimilar ones? Write your analysis as a pdf file.\n",
    "   \n",
    "- This function does not have any return. Just print out the result if asked.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guideline##\n",
    "- Following the solution template provided below. Use __main__ block to test your functions\n",
    "- Save your code into a python file (e.g. assign2.py) that can be run in a python 3 environment. In Jupyter Notebook, you can export notebook as .py file in menu \"File->Download as\".\n",
    "- Make sure you have all import statements. To test your code, open a command window in your current python working folder, type \"python assign2.py\" to see if it can run successfully.\n",
    "- **Each homework assignment should be completed independently. Never ever copy others' work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1\n",
      "[[3 1 5 4 2]\n",
      " [4 0 3 2 5]\n",
      " [2 5 4 3 1]]\n",
      "\n",
      "Q2\n",
      "         id         creationdate  score  viewcount  \\\n",
      "0  48046500  2018-01-01 00:35:52      1        126   \n",
      "1  48046520  2018-01-01 00:41:07      1        131   \n",
      "2  48046643  2018-01-01 01:26:14      0        487   \n",
      "3  48046647  2018-01-01 01:27:54      0        136   \n",
      "4  48046766  2018-01-01 02:07:39     -3         52   \n",
      "\n",
      "                                               title  answercount  \\\n",
      "0                          Array in Pandas Dataframe            1   \n",
      "1                       Pandas manual label encoding            0   \n",
      "2  Write Pandas Dataframe to CSV with a variable ...            1   \n",
      "3  Adding a time index to a pandas dataframe from...            1   \n",
      "4  How to convert values of a pandas data frame c...            1   \n",
      "\n",
      "                                                tags            quest_name  \n",
      "0                               python, json, pandas                  Tobi  \n",
      "1                                     python, pandas  Marvin Taschenberger  \n",
      "2       pandas, operating-system, export-to-csv, sys                  Matt  \n",
      "3  python, pandas, datetime, indexing, google-fin...             pmillerhk  \n",
      "4                                     python, pandas           user2277675  \n",
      "                                                 title  viewcount\n",
      "75   Python: Pandas pd.read_excel giving ImportErro...      33297\n",
      "163                     Python convert object to float      16658\n",
      "886                  Subtract two columns in dataframe      11176\n",
      "\n",
      "Top 5 users, who asked the most questions:\n",
      "Shuvayan Das    7\n",
      "Rahul rajan     7\n",
      "Danny W         6\n",
      "el323           6\n",
      "Hana            5\n",
      "Name: quest_name, dtype: int64\n",
      "\n",
      "Based on first_tag column:\n",
      "For python:\n",
      "amin        5.000000\n",
      "mean      428.670091\n",
      "amax    33297.000000\n",
      "Name: viewcount, dtype: float64\n",
      "For pandas:\n",
      "amin      14.0000\n",
      "mean     454.6875\n",
      "amax    4499.0000\n",
      "Name: viewcount, dtype: float64\n",
      "For dataframe:\n",
      "amin   NaN\n",
      "mean   NaN\n",
      "amax   NaN\n",
      "Name: viewcount, dtype: float64\n",
      "\n",
      "Based on tags column:\n",
      "For python:\n",
      "amin        5.000000\n",
      "mean      417.278794\n",
      "amax    33297.000000\n",
      "Name: viewcount, dtype: float64\n",
      "For pandas:\n",
      "amin        5.000\n",
      "mean      420.402\n",
      "amax    33297.000\n",
      "Name: viewcount, dtype: float64\n",
      "For dataframe:\n",
      "amin      16.000000\n",
      "mean     347.381818\n",
      "amax    5753.000000\n",
      "Name: viewcount, dtype: float64\n",
      "\n",
      "first_tag    arrays  c++  django  excel  function  json  machine-learning  \\\n",
      "answercount                                                                 \n",
      "0                 0    0       0      1         0     0                 0   \n",
      "1                 1    1       0      1         1     0                 0   \n",
      "2                 0    0       1      1         0     0                 1   \n",
      "3                 0    0       0      0         0     1                 0   \n",
      "4                 0    0       0      0         0     0                 0   \n",
      "5                 0    0       0      0         0     0                 0   \n",
      "7                 0    0       0      0         0     0                 0   \n",
      "\n",
      "first_tag    pandas  postgresql  python  python-2.7  python-3.x  regex  sql  \\\n",
      "answercount                                                                   \n",
      "0                11           0      98           1           9      0    0   \n",
      "1                37           1     455           5          20      1    1   \n",
      "2                13           0     232           3           6      0    0   \n",
      "3                 2           0      64           0           3      0    0   \n",
      "4                 1           0      21           0           0      0    0   \n",
      "5                 0           0       3           0           0      0    0   \n",
      "7                 0           0       3           0           0      0    0   \n",
      "\n",
      "first_tag    xml  \n",
      "answercount       \n",
      "0              1  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "5              0  \n",
      "7              0  \n",
      "\n",
      "For python,\n",
      "how many questions were not answered?: 98\n",
      "how many questions were answered once?: 455\n",
      "how many questions were anasered twice?: 232\n",
      "\n",
      "\n",
      "Q3\n",
      "(1000, 23)\n",
      "Top 5 words for first 20 questions:\n",
      "q1:dataframe,pandas,array,in,\n",
      "q2:encoding,label,pandas,manual,\n",
      "q3:pathway,in,name,variable,a,\n",
      "q4:adding,google,from,dataframe,pandas,\n",
      "q5:at,unique,all,values,,numeric,\n",
      "q6:create,a,of,columns,from,\n",
      "q7:conditions,under,columns,setting,of,\n",
      "q8:file,csv,in,column,date,\n",
      "q9:dictionary,a,in,defined,are,\n",
      "q10:pandas,python,with,read,file,\n",
      "q11:python,in,times,multiple,used,\n",
      "q12:group,by,records,json,into,\n",
      "q13:pandas,with,processing,nltk-based,text,\n",
      "q14:column,particular,a,in,device_id,\n",
      "q15:layout,another,to,dataframe,transform,\n",
      "q16:dataframes,different,of,columns,2,\n",
      "q17:names,similar,with,columns,data-frame,\n",
      "q18:json,a,as,template,flask,\n",
      "q19:[pandas],dataframe,same,the,on,\n",
      "q20:columns,multiple,label,binarizer:,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Structure of your solution to Assignment 1 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_data(filepath):\n",
    "    \n",
    "    que_df = pd.read_csv(filepath, header=0)\n",
    "    \n",
    "    # questions with top 3 viewcounts among those answered questions\n",
    "    print((que_df.sort_values(by=\"viewcount\", ascending=False)[que_df.answercount>0])[['title','viewcount']].iloc[:3])\n",
    "    print(\"\")\n",
    "    \n",
    "    # top 5 users (i.e. quest_name) who asked the most questions\n",
    "    print(\"Top 5 users, who asked the most questions:\")\n",
    "    print(que_df.quest_name.value_counts()[:5])\n",
    "    print(\"\")\n",
    "    \n",
    "    # first_tag column\n",
    "    que_df['first_tag'] = que_df[\"tags\"].apply(lambda x:x.split(\",\")[0])\n",
    "\n",
    "    # from 'first_tag' column ######################\n",
    "    # mean, max, min viewcount for python:\n",
    "    print(\"Based on first_tag column:\")\n",
    "    print(\"For python:\")\n",
    "    print((que_df['viewcount'][que_df.first_tag == 'python']).agg([ np.min, np.mean, np.max]))    \n",
    "    # mean, max, min viewcount for pandas:\n",
    "    print(\"For pandas:\")\n",
    "    print((que_df['viewcount'][que_df.first_tag == 'pandas']).agg([ np.min, np.mean, np.max]))    \n",
    "    # mean, max, min viewcount for dataframe:\n",
    "    print(\"For dataframe:\")\n",
    "    print((que_df['viewcount'][que_df.first_tag == 'dataframe']).agg([ np.min, np.mean, np.max]))\n",
    "    print(\"\")\n",
    "    \n",
    "    # from 'tags' column ######################\n",
    "    # mean, max, min viewcount for python:\n",
    "    print(\"Based on tags column:\")\n",
    "    print(\"For python:\")\n",
    "    print((que_df['viewcount'][que_df.tags.apply(lambda x: 'python' in x)]).agg([ np.min, np.mean, np.max]))\n",
    "    # mean, max, min viewcount for pandas:\n",
    "    print(\"For pandas:\")\n",
    "    print((que_df['viewcount'][que_df.tags.apply(lambda x: 'pandas' in x)]).agg([ np.min, np.mean, np.max]))\n",
    "    # mean, max, min viewcount for dataframe:\n",
    "    print(\"For dataframe:\")\n",
    "    print((que_df['viewcount'][que_df.tags.apply(lambda x: 'dataframe' in x)]).agg([ np.min, np.mean, np.max]))\n",
    "    print(\"\")\n",
    "    \n",
    "    cr_tab = pd.crosstab(index=que_df.answercount, columns=[que_df.first_tag])\n",
    "    print(cr_tab)\n",
    "    print(\"\")\n",
    "    print(\"For python,\")\n",
    "    print(\"how many questions were not answered?: %d\"%cr_tab['python'].loc[0])\n",
    "    print(\"how many questions were answered once?: %d\"%cr_tab['python'].loc[1])\n",
    "    print(\"how many questions were anasered twice?: %d\"%cr_tab['python'].loc[2])\n",
    "    print(\"\")    \n",
    "    \n",
    "def analyze_tf_idf(arr,K):\n",
    "    \n",
    "    doc_len = np.sum(arr, axis=1)[:,None]\n",
    "    \n",
    "    # term frequency\n",
    "    tf = arr / doc_len\n",
    "    \n",
    "    # doc frequency\n",
    "    df = np.sum(np.where(arr>0,1,0), axis=0)\n",
    "    \n",
    "    # tfidf\n",
    "    tf_idf = tf / (np.log(df)+1)\n",
    "\n",
    "    # boundary condition to make sure that K is in given range\n",
    "    if (K <= 0 or K > arr.shape[1]):\n",
    "        return tf_idf, \"Please enter valid K value!\" \n",
    "    \n",
    "    # indices of words with top K largest values in the tf_idf array\n",
    "    top_k = np.argsort(tf_idf, axis=1)[:,::-1][:,:K]\n",
    "    \n",
    "    return tf_idf, top_k\n",
    "\n",
    "\n",
    "def analyze_corpus(filepath):\n",
    "    \n",
    "    que_df = pd.read_csv(filepath, header=0)\n",
    "    \n",
    "    # converting all documents into tokens for title column\n",
    "    que_df.title = (que_df.title.apply(lambda x: x.lower().split(\" \")))\n",
    "    \n",
    "    m = pd.DataFrame(que_df.title.apply(lambda x: np.unique(x, return_counts=True)[1]))\n",
    "    \n",
    "    # creating array with all 0's\n",
    "    result = np.zeros((m.title.size, m.title.apply(lambda x: len(x)).max()))\n",
    "    print(result.shape)\n",
    "    \n",
    "    # filling available values(unique token counts) in result array\n",
    "    for i in range(m.title.size): \n",
    "        v = m.title[i]\n",
    "        for j in range(len(v)):\n",
    "            result[i,j] = v[j]\n",
    "            \n",
    "    # analyzing result array and creating tfidf matrix        \n",
    "    tf_idf, indices = analyze_tf_idf(result, 5)\n",
    "    \n",
    "    # extracting top 5 words(if available) for first 20 questions \n",
    "    print(\"Top 5 words for first 20 questions:\")\n",
    "    for i in range(len(indices[:20])):\n",
    "        print(\"q%d\"%(i+1), end=\":\")\n",
    "        for j in range(5):\n",
    "            if j == len(que_df.title[i]):\n",
    "                continue            \n",
    "            print(que_df.title[i][indices[i][j]], end=',')\n",
    "        print(\"\")  \n",
    "\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    arr=np.array([[0,1,0,2,0,1],[1,0,1,1,2,0],[0,0,2,0,0,1]])\n",
    "    \n",
    "    print(\"\\nQ1\")\n",
    "    tf_idf, top_k=analyze_tf_idf(arr,5)\n",
    "    print(top_k)\n",
    "    \n",
    "    print(\"\\nQ2\")\n",
    "    analyze_data('question.csv')\n",
    "    \n",
    "    # test question 3\n",
    "    print(\"\\nQ3\")\n",
    "    analyze_corpus('question.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
