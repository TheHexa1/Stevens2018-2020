{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en')\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "def extract(text):    \n",
    "    result = None\n",
    "    \n",
    "    #pattern to be matched in regex function\n",
    "    pattern = r'\\s*(.*), (.*[^,]),? \\(.*(\\d{4}).*(\\d{3},\\d{3})'    \n",
    "    result = re.findall(pattern, text)    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "def tokenize(doc, lemmatized=False, no_stopword=False):\n",
    "    tokens =[]\n",
    "    \n",
    "    doc_ = nlp(doc)   \n",
    "    \n",
    "    for token in doc_:\n",
    "        if no_stopword:\n",
    "            if token.is_stop:\n",
    "                continue\n",
    "\n",
    "        if lemmatized:\n",
    "            tokens.append(token.lemma_)\n",
    "        else:\n",
    "            tokens.append(token.text)    \n",
    "    return tokens\n",
    "\n",
    "def get_similarity(q1, q2, lemmatized=False, no_stopword=False):\n",
    "    sim = []   \n",
    "    \n",
    "    #combine all questions\n",
    "    total_q = q1 + q2\n",
    "    \n",
    "    #get combined tf-idf matrix\n",
    "    tf_idf = tfidf(total_q, lemmatized, no_stopword)\n",
    "    \n",
    "    #we will get 1000x1000 similarity matrix with q1 and q2 list concated. \n",
    "    #hence, slicing from 500 to get pairwise similarity for each q1 and q2                                      \n",
    "    pairwise_matrix = 1-distance.squareform(distance.pdist(tf_idf, 'cosine'))[:500,500:]\n",
    "    \n",
    "    sim = [pairwise_matrix[i][i] for i in range(500)]\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def predict(sim, ground_truth, threshold=0.5):\n",
    "    predict = []\n",
    "    recall = None\n",
    "    \n",
    "    for score in sim:\n",
    "        if score > threshold:\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "            \n",
    "    tp = getTruePositives(predict, ground_truth)      \n",
    "    recall = tp/list(ground_truth).count(1)            \n",
    "    return predict, recall\n",
    "\n",
    "#get the token count for given document\n",
    "def get_doc_tokens(doc, lemmatized, no_stopword):\n",
    "    tokens=[token for token in tokenize(doc.lower(), lemmatized, no_stopword)]\n",
    "    \n",
    "    token_count={token:tokens.count(token) for token in set(tokens)}\n",
    "    return token_count\n",
    "\n",
    "#get tf-idf matrix\n",
    "def tfidf(docs, lemmatized, no_stopword):\n",
    "    # process all documents to get list of tokens\n",
    "    docs_tokens={idx:get_doc_tokens(doc, lemmatized, no_stopword) \\\n",
    "             for idx,doc in enumerate(docs)}    \n",
    "\n",
    "    # get document-term matrix\n",
    "    dtm=pd.DataFrame.from_dict(docs_tokens, orient=\"index\" )\n",
    "    dtm=dtm.fillna(0)\n",
    "      \n",
    "    # get normalized term frequency (tf) matrix        \n",
    "    tf=dtm.values\n",
    "    doc_len=tf.sum(axis=1)\n",
    "    tf=np.divide(tf.T, doc_len).T\n",
    "    \n",
    "    # get idf\n",
    "    df=np.where(tf>0,1,0)\n",
    "    smoothed_idf=np.log(np.divide(len(docs)+1, np.sum(df, axis=0)+1))+1        \n",
    "    smoothed_tf_idf=normalize(tf*smoothed_idf)    \n",
    "    return smoothed_tf_idf\n",
    "\n",
    "#count number of true positives\n",
    "def getTruePositives(predictions, ground_truth):    \n",
    "    tp = 0\n",
    "            \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 1 and ground_truth[i] == 1:\n",
    "            tp += 1\n",
    "            \n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "def evaluate(sim, ground_truth, thresold=0.5):\n",
    "    precision = None\n",
    "    recall = None\n",
    "    \n",
    "    predictions, recall = predict(sim, ground_truth, thresold)    \n",
    "    tp = getTruePositives(predictions, ground_truth)    \n",
    "    precision = tp/predictions.count(1)        \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Test Q1 #####\n",
      "\n",
      "[('Grant Cornwell', 'College of Wooster', '2015', '911,651'), ('Marvin Krislov', 'Oberlin College', '2016', '829,913'), ('Mark Roosevelt', 'Antioch College', '2015', '507,672'), ('Laurie Joyner', 'Wittenberg University', '2015', '463,504'), ('Richard Giese', 'University of Mount Union', '2015', '453,800')]\n",
      "\n",
      "##### Test Q2 #####\n",
      "\n",
      "lemmatized: No, no_stopword: No\n",
      "0.6847826086956522\n",
      "\n",
      "lemmatized: Yes, no_stopword: No\n",
      "0.8043478260869565\n",
      "\n",
      "lemmatized: No, no_stopword: Yes\n",
      "0.7119565217391305\n",
      "\n",
      "lemmatized: Yes, no_stopword: Yes\n",
      "0.7717391304347826\n",
      "\n",
      "##### Test Q3 #####\n",
      "\n",
      "Precision:0.4797297297297297\n",
      "Recall:0.7717391304347826\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Test Q1\n",
    "    text='''Following is total compensation for other presidents at pr\n",
    "    ivate colleges in Ohio in 2015:\n",
    "    \n",
    "    Grant Cornwell, College of Wooster (left in 2015): $911,651\n",
    "    Marvin Krislov, Oberlin College (left in 2016): $829,913\n",
    "    Mark Roosevelt, Antioch College, (left in 2015): $507,672\n",
    "    Laurie Joyner, Wittenberg University (left in 2015): $463,504\n",
    "    Richard Giese, University of Mount Union (left in 2015): $453,800'''\n",
    "    \n",
    "    print(\"##### Test Q1 #####\\n\")\n",
    "    print(extract(text))\n",
    "    \n",
    "    data=pd.read_csv(\"quora_duplicate_question_500.csv\",\n",
    "    header=0)\n",
    "    q1 = data[\"q1\"].values.tolist()\n",
    "    q2 = data[\"q2\"].values.tolist()\n",
    "    \n",
    "    # Test Q2\n",
    "    print(\"\\n##### Test Q2 #####\")\n",
    "    print(\"\\nlemmatized: No, no_stopword: No\")    \n",
    "    sim = get_similarity(q1,q2)\n",
    "    pred, recall=predict(sim, data[\"is_duplicate\"].values)    \n",
    "    print(recall)\n",
    "\n",
    "    print(\"\\nlemmatized: Yes, no_stopword: No\")    \n",
    "    sim = get_similarity(q1,q2, True)\n",
    "    pred, recall=predict(sim, data[\"is_duplicate\"].values)    \n",
    "    print(recall)\n",
    "\n",
    "    print(\"\\nlemmatized: No, no_stopword: Yes\")    \n",
    "    sim = get_similarity(q1,q2, False, True)\n",
    "    pred, recall=predict(sim, data[\"is_duplicate\"].values)    \n",
    "    print(recall)\n",
    "\n",
    "    print(\"\\nlemmatized: Yes, no_stopword: Yes\")    \n",
    "    sim = get_similarity(q1,q2, True, True)\n",
    "    pred, recall=predict(sim, data[\"is_duplicate\"].values)\n",
    "    print(recall)\n",
    "    \n",
    "    # Test Q3. Get similarity score, set threshold, and then\n",
    "    print(\"\\n##### Test Q3 #####\\n\")\n",
    "    prec, rec = evaluate(sim, data[\"is_duplicate\"].values, 0.5)    \n",
    "    print(\"Precision:{}\\nRecall:{}\".format(prec,rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0, 0), 1)\n",
      "((0, 1), 2)\n",
      "((1, 0), 3)\n",
      "((1, 1), 4)\n",
      "((2, 0), 5)\n",
      "((2, 1), 6)\n"
     ]
    }
   ],
   "source": [
    "text='''Following is total compensation for other presidents at pr\n",
    "    ivate colleges in Ohio in 2015:\n",
    "    \n",
    "    Grant Cornwell, College of Wooster (left in 2015): $911,651\n",
    "    Marvin Krislov, Oberlin College (left in 2016): $829,913\n",
    "    Mark Roosevelt, Antioch College, (left in 2015): $507,672\n",
    "    Laurie Joyner, Wittenberg University (left in 2015): $463,504\n",
    "    Richard Giese, University of Mount Union (left in 2015): $453,800'''\n",
    "\n",
    "pattern = r'    (.*), (.*[^,]),? \\(.*(\\d{4}).*(\\d{3},\\d{3})'\n",
    "# pattern = r'(.*): '\n",
    "    \n",
    "# print(re.findall(pattern, text))\n",
    "\n",
    "data=pd.read_csv(\"quora_duplicate_question_500.csv\",header=0)\n",
    "data.head(3)\n",
    "\n",
    "a =np.array([[1,2],[3,4],[5,6]])\n",
    "for v in np.ndenumerate(a):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:0.4797297297297297\n",
      "Recall:0.7717391304347826\n"
     ]
    }
   ],
   "source": [
    "prec, rec = evaluate(sim, data[\"is_duplicate\"].values, 0.5)    \n",
    "print(\"Precision:{}\\nRecall:{}\".format(prec,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** t=0.900000 *****\n",
      "\n",
      "lemmatized: No, no_stopword: No\n",
      "Precision:0.8\n",
      "Recall:0.10869565217391304\n",
      "\n",
      "lemmatized: Yes, no_stopword: No\n",
      "Precision:0.7647058823529411\n",
      "Recall:0.14130434782608695\n",
      "\n",
      "lemmatized: No, no_stopword: Yes\n",
      "Precision:0.6888888888888889\n",
      "Recall:0.16847826086956522\n",
      "\n",
      "lemmatized: Yes, no_stopword: Yes\n",
      "Precision:0.6101694915254238\n",
      "Recall:0.1956521739130435\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"quora_duplicate_question_500.csv\",\n",
    "    header=0)\n",
    "q1 = data[\"q1\"].values.tolist()\n",
    "q2 = data[\"q2\"].values.tolist()\n",
    "\n",
    "t=9\n",
    "# for t in range(1,9):\n",
    "print(\"\\n***** t=%f *****\"%float(t/10))\n",
    "print(\"\\nlemmatized: No, no_stopword: No\")\n",
    "sim = get_similarity(q1,q2)\n",
    "prec, rec = evaluate(sim, data[\"is_duplicate\"].values, t/10)    \n",
    "print(\"Precision:{}\\nRecall:{}\".format(prec,rec))\n",
    "\n",
    "print(\"\\nlemmatized: Yes, no_stopword: No\")    \n",
    "sim = get_similarity(q1,q2, True)\n",
    "prec, rec = evaluate(sim, data[\"is_duplicate\"].values, t/10)    \n",
    "print(\"Precision:{}\\nRecall:{}\".format(prec,rec))\n",
    "\n",
    "print(\"\\nlemmatized: No, no_stopword: Yes\")    \n",
    "sim = get_similarity(q1,q2, False, True)\n",
    "prec, rec = evaluate(sim, data[\"is_duplicate\"].values, t/10)    \n",
    "print(\"Precision:{}\\nRecall:{}\".format(prec,rec))\n",
    "\n",
    "print(\"\\nlemmatized: Yes, no_stopword: Yes\")    \n",
    "sim = get_similarity(q1,q2, True, True)\n",
    "prec, rec = evaluate(sim, data[\"is_duplicate\"].values, t/10)    \n",
    "print(\"Precision:{}\\nRecall:{}\".format(prec,rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
